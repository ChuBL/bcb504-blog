---
title: "Assignment 2: Your Data Ver2.0"
author: "Jiyin Zhang"
subtitle: "Describing the dataset"
date: "2023-02-07"
format: html
---

## MY DATASET

This dataset is generated based on the elements coexistence counts from Mindat.org database. The original data source is retrieved via Mindat API and stored in JSON format. Then after data pre-process and data cleaning steps, the retrieved data is cured and stored in CSV format. The dataset can be accessed at the [Github repository](https://github.com/ChuBL/BCB-504-Foundations-of-Data-Visualization/tree/main/assg%232), in the name of **mineral.csv**.

<!-- ::: callout-note -->

<!-- The CSV file of dataset is a concatenated version of 72 separate spread sheets of element triplets coexistence values. Each spread sheet has 2 + 72 columns, the first column indicates the background element, which should remain the same throughout each separate sheet. The second column records the second dimension of the element triplets Then the third dimension of elements are listed by the remaining columns. The value of cell $(i, j)$ indicating the coexistence amount of three elements: the first two elements in $(i, 0)$ and $(i, 1)$, and the third element in $(0, j)$. -->

<!-- ::: -->

### Data Collection

The dataset was retrieved via Mindat API as a JSON file. In the data preprocessing step, the elements information are extracted in a new JSON file, in which some of the hierarchical structures have been removed in convenience of python's `to_csv` function. Then the exported csv file can be read directly with R's `read.csv` function.

## IMPORTING THE DATA

I'm going to use the built-in `read.csv` package to import CSV file.

```{r}
#| code-fold: true
#| code-summary: "Code"
#| output: false
library(tidyverse)
# result <- read.csv(file = 'total_elements_mindat.csv')
result <- read.csv(file = 'mineral.csv')
```

The `glimpse` command in the `Tidyverse` package is a nice way to summarize the data frame:

```{r}
#| code-fold: true
#| code-summary: "Code"
glimpse(result)
```

## DESCRIBE THE DATA

### Data Set Type

The dataset is stored as a great **Flat Table**, the items are 5883 mineral species from OpenMindat data server, and the columns representing the corresponding attributes.

```{r}
#| code-fold: true
#| code-summary: "Mineral Species Attributes"
c('id', 'name', 'elements', 'sigelements', 'yeardiscovery', 'hmin', 'hmax', 'hardtype', 'specificgravity', 'strunz10ed1', 'strunz10ed2', 'strunz10ed3', 'strunz10ed4', 'dana8ed1', 'dana8ed2', 'dana8ed3', 'dana8ed4')
```

### Attribute Types

The attributes of the data are recorded in a 2-dimensional format, therefore the data frame rows will looks similar to the result of `glimpse` function. The 'id' field is in a strict ascending order, while not continuous. The 'id' field of each row is determined by the website managers or data providers, therefore it has nothing to do with some standard identifications. The 'names' field indicates the IMA approved mineral species names. The 'elements' and 'sigelements' fields indicating the elements of the mineral chemical formual, while the 'sigelement' is determined by some significant elements as a subset of 'elements'. In compatable with csv format, the elements in this field are separated by hyphens $-$.

```{r}
#| code-fold: true
#| code-summary: "Code"
head(result)
```

## Visualization

### The correaltion between elements and hardness

```{r}
Elements <- c('H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Cs', 'Ba', 'La', 'Ce', 'Nd', 'Sm', 'Gd', 'Dy', 'Er', 'Yb', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'U')
library("tidyverse")

df <- data.frame(Elements)
df1 <- df %>%
  add_column(hmin = NA, hmin_mineral = NA, hmax = NA, hmax_mineral = NA, hmean = NA)

# for (row in 1:nrow(result)) {
#     mineral_name <- result[row, "name"]
#     elements <- str_extract_all(
#       result[row, "elements"], regex("(?<=-)[A-Z]+[a-z]*(?=-)")
#       )
# 
#     hmin <- result[row, "hmin"]
#     for (element in elements){
#         comparing_hmin <- df1[df1$Elements == element, 'hmin']
#         if (is.na(comparing_hmin)){
#           df1[df1$Elements == element, 'hmin'] <- hmin
#         }
#     }
#     # hmax <- result[row, "hmax"]
# }

print(df1)
print(df1[df1$Elements == 'H', 'hmin'])

```

```{r}
comparing_hmin <- df1[df1$Elements == 'H', 'hmin']
print(comparing_hmin)
if (is.na(comparing_hmin)){
  # df1[df1$Elements == element, 'hmin'] <- hmin
  print('hello')
}



elements <- str_extract_all(
      result[1, "elements"], regex("(?<=-)[A-Z]+[a-z]*(?=-)")
      )
print(elements)
# for (element in elements){
#   comparing_name <- df1[df1$Elements == element, 'Elements']
#   #v comparing_hmin <- df1[df1$Elements == element, 'hmin']
#   #print(element, sep = '\n')
#   print(comparing_name, sep = '\n')
#   #cat(comparing_hmin, sep = '\n')
# }


print(class(elements))
for (i in 1:length(elements)){
  print(elements[i])
  print('hello')
  }

for (element in elements){
  print(element)
  print('hello')
 }
  
# comparing_hmin <- df1[df1$Elements == 'H', 'hmin']
# print(comparing_hmin)
# print(class(comparing_hmin))
# if (is.na(comparing_hmin)){
#   print('test')
# }


# x <- c('-Ce-Na-Si-O-P-C-S-')
# y <- str_extract_all(x, regex("(?<=-)[A-Z]+[a-z]*(?=-)"))
# for (item in y){
#   cat(item, sep="\n")
# }
#   
# 
# primes_list <- list(2, 3, 5, 7, 11, 13)

# # loop version 1
# for (p in primes_list) {
#   print(p)
# }
```

## Question

::: callout-note
<del>I have no idea why the render result of this `.qmd` file failed to adapt to the html style.</del>

The problem is that the `.qmd` file shall not consist of the hashtag \# symbol.

Another issue fixed is that the json file is originally contains 5883 items, which should be converted into 5883 rows of csv items. While the converting results shows there were over 5900 rows. The reason for this problem is that there are some annoying `\n`s in the attributes, which will end up with new rows in the exported csv file. I fixed this issue by simply removing all the `\n`s in the json file.
:::
