{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"BCB 520 - Midterm Pokemon Portfolio Post\"\n",
        "author: \"Jiyin Zhang\"\n",
        "subtitle: \"Road to Masters\"\n",
        "date: \"2023-03-30\"\n",
        "categories: [Assignment, DataViz, Smogon, Pokemon Showdown]\n",
        "image: image_j28MHAY0_1680213973861_raw.jpeg\n",
        "code-fold: true\n",
        "code-tools: true\n",
        "description: \"Zapping Through the 10,000,000 Pokemon Battles\"\n",
        "format: html\n",
        "---"
      ],
      "id": "76f94c95"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collect the data"
      ],
      "id": "62173e0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "#| echo: false\n",
        "# import os\n",
        "# import requests\n",
        "# from lxml import html\n",
        "# from pathlib import Path\n",
        "# import sys\n",
        "# \n",
        "# url = \"https://www.smogon.com/stats/\"\n",
        "# data_dir = os.path.join(os.getcwd(), \"data\")\n",
        "# \n",
        "# def download_files(url, dir_path=data_dir):\n",
        "#     # use pathlib to create the directory whether the parent directory exists or not\n",
        "#     Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "# \n",
        "#     response = requests.get(url)\n",
        "#     parsed_body = html.fromstring(response.content)\n",
        "#    \n",
        "#     for index in range(1, 65535):\n",
        "#         try:\n",
        "#             link = parsed_body.xpath(\"/html/body/pre/a[{index}]\".format(index=index))[0]\n",
        "#         except IndexError:\n",
        "#             break\n",
        "#         text = link.text\n",
        "#         if \"..\" in text:\n",
        "#             continue\n",
        "#         if \".\" in text:\n",
        "#             file_url = url + text\n",
        "#             file_path = os.path.join(dir_path, file_url.split(\"/\")[-1])\n",
        "#             print(\"Downloading\", file_url)\n",
        "#             r = requests.get(file_url)\n",
        "#             with open(file_path, \"wb\") as f:\n",
        "#                 f.write(r.content)\n",
        "#             print(\"Downloaded\", file_url)\n",
        "#             #sys.exit()\n",
        "#         else:\n",
        "#             new_url = url + text\n",
        "#             new_dir = os.path.join(dir_path, text)\n",
        "#             download_files(new_url, new_dir)\n",
        "# \n",
        "# \n",
        "# def batch_download_by_year(YEAR):\n",
        "#     response = requests.get(url)\n",
        "#     parsed_body = html.fromstring(response.content)\n",
        "#     for index in range(1, 65535):\n",
        "#         try:\n",
        "#             link = parsed_body.xpath(\"/html/body/pre/a[{index}]\".format(index=index))[0]\n",
        "#         except IndexError:\n",
        "#             break\n",
        "#         text = link.text\n",
        "#         if str(YEAR) in text:\n",
        "#             print(\"Downloading\", YEAR)\n",
        "#             new_url = url + text\n",
        "#             new_dir = os.path.join(data_dir, str(YEAR), text)\n",
        "#             download_files(new_url, new_dir)\n",
        "# \n",
        "#     year_url = url + str(YEAR) + \"/\"\n",
        "#     year_dir = os.path.join(data_dir, str(YEAR))\n",
        "#     download_files(year_url, year_dir)\n",
        "#     \n",
        "# \n",
        "# def _test_parse():\n",
        "#     response = requests.get(url)\n",
        "#     parsed_body = html.fromstring(response.content)\n",
        "#     link = parsed_body.xpath(\"/html/body/pre/a[999]\")[0]\n",
        "#     #text = link.text\n",
        "#     #print(text)\n",
        "# \n",
        "# if __name__ == \"__main__\":\n",
        "#     batch_download_by_year(2023)"
      ],
      "id": "f17ddce2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I managed to grab a huge bunch of data from the Smogon forum since it is hard to collect similar Pokemon battle data from official websites, except for some crazy poke fans who can manually recognize and record the Pokemon ranking information and player teams from the official competition videos. \n",
        "\n",
        "I am unfamiliar with some Pokemon names and skills in English, which inevitably lowers my efficiency in parsing the data. At the same time, the good news is the dataset size is overwhelming, which means I don't have to bother particular Pokemons but the whole tendency patterns.\n",
        "\n",
        "The collected data can be accessed from this [source](https://www.smogon.com/stats/). My local data collection is managed accordingly to the file hierarchy of this straightforward website.\n",
        "\n",
        "\n",
        "My current work focuses on the data recorded in 2023. The Pokemon battle data are stored in `.txt` and `.json` formats. I am working on reading some forum threads about the data discussion and explanations. The next plan is to convert the interesting part of the data into an R data frame and end up with visualizations."
      ],
      "id": "99ee97ed"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}