{
  "hash": "230ec6cf960c930d03f732d8d40c3501",
  "result": {
    "markdown": "---\ntitle: \"End of the Term: Visualizing the Death of COVID-19\"\nauthor: \"Jiyin Zhang\"\nsubtitle: \" Creating Effective Visualizations for COVID-19 Death Cases\"\ndate: \"2023-05-08\"\ncategories: [Visualization, COVID-19, Observable, Assignment]\nimage: qJaIxHR4S5Zun3z8veat--1--n8qpv.jpg\ncode-fold: true\ncode-tools: true\ndescription: \"Discover the power of data visualization as we explore COVID-19 death cases in the United States through various charts.\"\nformat: html\n---\n\n# PREAMBLE\n<p style=\"color:red\">Covid-19.</p>\n\nThe COVID-19 pandemic has undoubtedly affected every aspect of our lives, and understanding its impact is crucial in our ongoing efforts to mitigate the spread of the virus and protect vulnerable populations. One valuable resource for understanding this impact is the dataset titled [\"Conditions Contributing to COVID-19 Deaths, by State and Age, Provisional 2020-2023\"](https://catalog.data.gov/dataset/conditions-contributing-to-deaths-involving-coronavirus-disease-2019-covid-19-by-age-group) which offers a comprehensive look at the health conditions and causes mentioned in conjunction with COVID-19 related deaths across different age groups and jurisdictions. \n\nIn this blog post, I will explore this dataset and showcase a series of visualizations that aim to provide greater insight into the patterns, trends, and relationships hidden within the data. Our visualizations will include a **state-wise stacked bar chart of ages of COVID-19 deaths**, an **animated visualization capturing the changing dynamics of deaths in each state**, an **interactive network chart connecting death age groups with the conditions leading to death**, and finally, a **choropleth map illustrating COVID-19 deaths by state**. By delving into these visualizations, I hope to not only improve our understanding of the pandemic's impact on various communities but also inspire data-driven decision-making in our ongoing fight against COVID-19. So, let's dive in and uncover the stories hidden within the data.\n\n\n# Data Preparation\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\n\n# Read the input CSV file\ninput_file = 'Conditions_Contributing_to_COVID-19_Deaths__by_State_and_Age__Provisional_2020-2023.csv'\ndf = pd.read_csv(input_file)\n\n# Split the DataFrame based on the \"Group\" column values\ndf_by_total = df[df['Group'] == 'By Total']\ndf_by_month = df[df['Group'] == 'By Month']\ndf_by_year = df[df['Group'] == 'By Year']\n\n# Write the DataFrames to separate CSV files\ndf_by_total.to_csv('by_total.csv', index=False)\ndf_by_month.to_csv('by_month.csv', index=False)\ndf_by_year.to_csv('by_year.csv', index=False)\n\ndef state_comparison():\n    # List of U.S. states\n    us_states = [\n        'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n        'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa',\n        'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n        'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n        'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma',\n        'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n        'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'\n    ]\n\n    # Read the CSV file\n    input_file = 'by_year.csv'\n    df = pd.read_csv(input_file)\n\n    # Extract unique state values from the 'State' column\n    unique_states_in_csv = df['State'].unique()\n\n    # Compare the unique state values with the U.S. states list\n    missing_states = set(us_states) - set(unique_states_in_csv)\n    extra_states = set(unique_states_in_csv) - set(us_states)\n\n    print(\"Missing states:\", missing_states)\n    print(\"Extra states:\", extra_states)\n\ndef state_filter(filename):\n    # Read the input CSV file\n    #input_file = 'Conditions_Contributing_to_COVID-19_Deaths__by_State_and_Age__Provisional_2020-2023.csv'\n    df = pd.read_csv(filename)\n\n    # Filter out rows with 'State' column having the value 'Puerto Rico'\n    filtered_df = df[df['State'] != 'Puerto Rico']\n\n    # Write the filtered DataFrame to a new CSV file\n    output_file = 'filtered_' + filename\n    filtered_df.to_csv(output_file, index=False)\n\nif __name__ == '__main__':\n    #state_comparison()\n    #state_filter('by_month.csv')\n```\n:::\n\n\nIn the data preparation stage, I utilized Python to divide the entire CSV file into three separate subfiles based on the granularity of time - by total, by year, and by month. I then applied a filter to verify the validity of values under the 'State' column. An unexpected subset for 'Puerto Rico' was discovered and subsequently discarded. Additionally, 'District of Columbia' and 'New York City' were singled out from the states.\n\nTo plot the choropleth, I found a mapping function for R that geocodes state names, including 'District of Columbia,' into a map with regions represented by longitudes and latitudes. Unfortunately, the function did not include New York City, so I had to exclude this part of the data when creating the choropleth visualization.\n\nIn addition to these preprocessing steps, I carried out further data cleansing tasks using Python, tailored to the specific requirements of each visualization task.\n\n\n# Visualizations\n\n## Bar Chart for COVID-19 Deaths by State and Age Group\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#library(viridisLite)\nlibrary(viridis)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# Read the CSV file\ndf <- read.csv(\"./piechart/filtered_by_total.csv\")\n\n\n# Group the data by state and age group\ndf_grouped <- aggregate(COVID.19.Deaths ~ State + Age.Group, data = df, sum)\n\n# Exclude the \"United States\" rows\ndf_grouped <- subset(df_grouped, State != \"United States\")\n\n# Order the states by total number of deaths\nstate_order <- with(df_grouped, reorder(State, -COVID.19.Deaths, sum))\n\n# Create the stacked bar chart\n\nggplot(df_grouped, aes(x = state_order, y = COVID.19.Deaths, fill = Age.Group)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"COVID-19 Deaths by State and Age Group\") +\n  xlab(\"State\") +\n  ylab(\"Number of Deaths\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme(legend.position = \"right\") +\n  guides(fill=guide_legend(title=\"Age Group\")) +\n  scale_fill_viridis(discrete = TRUE, option = \"viridis\", direction = -1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nThis visualization presents data from the *\"Conditions Contributing to COVID-19 Deaths, by State and Age, Provisional 2020-2023\"* dataset, which provides information on the number of COVID-19 deaths by state, age group, and time period. This visualization focuses on the total number of COVID-19 deaths by state and age group, using data from the \"By Total\" time period.\n\nThe bars in the chart represent the total number of COVID-19 deaths for each state and age group, with the color of each bar indicating the age group. The chart allows for easy comparison of the number of COVID-19 deaths between different states and age groups, with the height of each bar corresponding to the number of deaths.\n\nTo provide a clear representation of the data, the information for the United States as a whole has been filtered out from the visualization. This is because including it would compress the height of individual state bars, making it difficult to distinguish between the states.\n\n## Animated Visualization for COVID-19 Deaths in Each State\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nfrom datetime import datetime\n\n# Read the CSV file\ndf = pd.read_csv(\"filtered_by_month.csv\")\n\n# Define the US states list\nus_states = ['District of Columbia', 'New York City', 'Alabama', 'Alaska', 'Arizona', 'Arkansas', \n             'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', \n             'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n             'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n             'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n             'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia',\n             'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n\n# Exclude rows where the 'name' column is 'United States'\ndf = df[df['State'] != 'United States']\n\n# Extract the necessary columns and rename them\ndf = df[['Start Date', 'State', 'COVID-19 Deaths']]\ndf = df.rename(columns={'Start Date': 'date', 'State': 'name', 'COVID-19 Deaths': 'value'})\n\n# Convert the date column to datetime format\ndf['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y')\n\n# Format the date column as '1970-01-01'\ndf['date'] = df['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n\n# Add the category column using the US states list\ndf['category'] = df['name'].apply(lambda x: us_states.index(x))\n\n# Group the data by date, name, and category, and sum the values\ndf = df.groupby(['date', 'name', 'category'], as_index=False).sum()\n\n\n\n# Add the index column and reorder the columns\ndf.insert(0, 'index', range(1, len(df) + 1))\ndf = df[['index', 'date', 'name', 'category', 'value']]\n# Cast the index and name columns to string\ndf['index'] = df['index'].astype(str)\ndf['name'] = df['name'].astype(str)\n# Save the output to a CSV file\ndf.to_csv('./horizontal/output.csv', index=False)\n\n\nimport re\n\n# Read the CSV file\nwith open('output.csv', 'r') as file:\n    csv_data = file.read()\n\n# Define the regex pattern\npattern = r'(?<=,)([a-zA-Z ]+)(?=,)'\n\n# Define the replacement string\nreplace_str = r'\"\\1\"'\n\n# Replace the matches with the original text enclosed in quotes\ncsv_data = re.sub(pattern, replace_str, csv_data)\n\n# Write the updated CSV file\nwith open('output2.csv', 'w') as file:\n    file.write(csv_data)\n```\n:::\n\n\nThis visualization required significant data cleansing and adjustments to the code, which I didn't initially expect. I used the [`Zomstates.csv`](https://github.com/ProfessorPolymorphic/RobisonWebSite/blob/master/BCB520/posts/T8-MidtermExample/Zomstates.csv) as a reference to modify my csv file. I also employed regular expressions to add quotes around the State names to prevent spaces from causing issues in the code.\n\nMoreover, the visualization didn't work correctly when copying and pasting from the [`.qmd ` file](https://github.com/ProfessorPolymorphic/RobisonWebSite/blob/master/BCB520/posts/T8-MidtermExample/index.qmd). I made a modification in the function bars(svg) as follows:\n\n        <!-- .attr(\"x\", x(0)) -->\n        .attr(\"x\", -6)\n\nThe variable x(0) appeared unstable, causing many of the bars' x-axis positions to shift towards the center of the screen. Only a small portion of the data functioned correctly, starting from the left margin. I'm not entirely sure, but -6 might be related to the margin variable. Without this modification, the bars would start from the middle of the graph.\n\nI also found that the original animation speed was too fast for my data compared to the initial zombie data. I increased the duration tenfold to 250.\n\n\n```{ojs}\n\ndata = d3.csvParse(await FileAttachment(\"./horizontal/output2.csv\").text(), d3.autoType)\nviewof replay = html`<button>Replay`\n\n```\n\n```{ojs}\nchart = {\n  \n  replay;\n\n  const svg = d3.create(\"svg\")\n      .attr(\"viewBox\", [0, 0, width, height]);\n\n  const updateBars = bars(svg);\n  const updateAxis = axis(svg);\n  const updateLabels = labels(svg);\n  const updateTicker = ticker(svg);\n\n  yield svg.node();\n\n  for (const keyframe of keyframes) {\n    const transition = svg.transition()\n        .duration(duration)\n        .ease(d3.easeLinear);\n\n    // Extract the top bar’s value.\n    x.domain([0, keyframe[1][0].value]);\n\n    updateAxis(keyframe, transition);\n    updateBars(keyframe, transition);\n    updateLabels(keyframe, transition);\n    updateTicker(keyframe, transition);\n\n    invalidation.then(() => svg.interrupt());\n    await transition.end();\n  }\n}\n\n\nduration = 250\nn = 50\nk = 10\nnames = new Set(data.map(d => d.name))\n\n\ndatevalues = Array.from(d3.rollup(data, ([d]) => d.value, d => +d.date, d => d.name))\n  .map(([date, data]) => [new Date(date), data])\n  .sort(([a], [b]) => d3.ascending(a, b))\n  \n  \nfunction rank(value) {\n  const data = Array.from(names, name => ({name, value: value(name)}));\n  data.sort((a, b) => d3.descending(a.value, b.value));\n  for (let i = 0; i < data.length; ++i) data[i].rank = Math.min(n, i);\n  return data;\n}\n\nkeyframes = {\n  const keyframes = [];\n  let ka, a, kb, b;\n  for ([[ka, a], [kb, b]] of d3.pairs(datevalues)) {\n    for (let i = 0; i < k; ++i) {\n      const t = i / k;\n      keyframes.push([\n        new Date(ka * (1 - t) + kb * t),\n        rank(name => (a.get(name) || 0) * (1 - t) + (b.get(name) || 0) * t)\n      ]);\n    }\n  }\n  keyframes.push([new Date(kb), rank(name => b.get(name) || 0)]);\n  return keyframes;\n}\n\nnameframes = d3.groups(keyframes.flatMap(([, data]) => data), d => d.name)\n\nprev = new Map(nameframes.flatMap(([, data]) => d3.pairs(data, (a, b) => [b, a])))\n\nnext = new Map(nameframes.flatMap(([, data]) => d3.pairs(data)))\n\nfunction bars(svg) {\n  let bar = svg.append(\"g\")\n      .attr(\"fill-opacity\", 0.6)\n    .selectAll(\"rect\");\n\n  return ([date, data], transition) => bar = bar\n    .data(data.slice(0, n), d => d.name)\n    .join(\n      enter => enter.append(\"rect\")\n        .attr(\"fill\", color)\n        .attr(\"height\", y.bandwidth())\n        <!-- .attr(\"x\", x(0)) -->\n        .attr(\"x\", -6)\n        .attr(\"y\", d => y((prev.get(d) || d).rank))\n        .attr(\"width\", d => x((prev.get(d) || d).value) - x(0)),\n      update => update,\n      exit => exit.transition(transition).remove()\n        .attr(\"y\", d => y((next.get(d) || d).rank))\n        .attr(\"width\", d => x((next.get(d) || d).value) - x(0))\n    )\n    .call(bar => bar.transition(transition)\n      .attr(\"y\", d => y(d.rank))\n      .attr(\"width\", d => x(d.value) - x(0)));\n}\n\n\nfunction labels(svg) {\n  let label = svg.append(\"g\")\n      .style(\"font\", \"bold 12px var(--sans-serif)\")\n      .style(\"font-variant-numeric\", \"tabular-nums\")\n      .attr(\"text-anchor\", \"end\")\n    .selectAll(\"text\");\n\n  return ([date, data], transition) => label = label\n    .data(data.slice(0, n), d => d.name)\n    .join(\n      enter => enter.append(\"text\")\n        .attr(\"transform\", d => `translate(${x((prev.get(d) || d).value)},${y((prev.get(d) || d).rank)})`)\n        .attr(\"y\", y.bandwidth() / 2)\n        .attr(\"x\", -6)\n        .attr(\"dy\", \"-0.25em\")\n        .text(d => d.name)\n        .call(text => text.append(\"tspan\")\n          .attr(\"fill-opacity\", 0.7)\n          .attr(\"font-weight\", \"normal\")\n          .attr(\"x\", -6)\n          .attr(\"dy\", \"1.15em\")),\n      update => update,\n      exit => exit.transition(transition).remove()\n        .attr(\"transform\", d => `translate(${x((next.get(d) || d).value)},${y((next.get(d) || d).rank)})`)\n        .call(g => g.select(\"tspan\").tween(\"text\", d => textTween(d.value, (next.get(d) || d).value)))\n    )\n    .call(bar => bar.transition(transition)\n      .attr(\"transform\", d => `translate(${x(d.value)},${y(d.rank)})`)\n      .call(g => g.select(\"tspan\").tween(\"text\", d => textTween((prev.get(d) || d).value, d.value))))\n}\n\nfunction textTween(a, b) {\n  const i = d3.interpolateNumber(a, b);\n  return function(t) {\n    this.textContent = formatNumber(i(t));\n  };\n}\n\nformatNumber = d3.format(\",d\")\n\nfunction axis(svg) {\n  const g = svg.append(\"g\")\n      .attr(\"transform\", `translate(0,${margin.top})`);\n\n  const axis = d3.axisTop(x)\n      .ticks(width / 160)\n      .tickSizeOuter(0)\n      .tickSizeInner(-barSize * (n + y.padding()));\n\n  return (_, transition) => {\n    g.transition(transition).call(axis);\n    g.select(\".tick:first-of-type text\").remove();\n    g.selectAll(\".tick:not(:first-of-type) line\").attr(\"stroke\", \"white\");\n    g.select(\".domain\").remove();\n  };\n}\n\nfunction ticker(svg) {\n  const now = svg.append(\"text\")\n      .style(\"font\", `bold ${barSize}px var(--sans-serif)`)\n      .style(\"font-variant-numeric\", \"tabular-nums\")\n      .attr(\"text-anchor\", \"end\")\n      .attr(\"x\", width - 6)\n      .attr(\"y\", margin.top + barSize * (n - 0.45))\n      .attr(\"dy\", \"0.32em\")\n      .text(formatDate(keyframes[0][0]));\n\n  return ([date], transition) => {\n    transition.end().then(() => now.text(formatDate(date)));\n  };\n}\n\nformatDate = d3.utcFormat(\"%Y\")\n\ncolor = {\n  const scale = d3.scaleSequential(d3.interpolate(\"red\", \"blue\")).domain([1, 48]);\n  if (data.some(d => d.category !== undefined)) {\n    const categoryByName = new Map(data.map(d => [d.name, d.category]))\n    scale.domain(Array.from(categoryByName.values()));\n    return d => scale(categoryByName.get(d.name));\n  }\n  return d => scale(d.name);\n}\n\n\n<!-- color = { -->\n<!--   const scale = d3.scaleSequential(d3.interpolate(\"red\", \"blue\")).domain([1, 48]); -->\n<!--   if (data.some(d => d.category !== undefined)) { -->\n<!--     const categoryByName = new Map(data.map(d => [d.name, d.category])); -->\n<!--     const categories = Array.from(categoryByName.values()).filter((d, i, arr) => arr.indexOf(d) === i); -->\n<!--     const scaleByCategory = typeof categories[0] === \"number\" ?  -->\n<!--       d3.scaleSequential(d3.interpolateSpectral).domain(d3.extent(categories)) : -->\n<!--       d3.scaleOrdinal().domain(categories).range(d3.quantize(d3.interpolateSpectral, categories.length)); -->\n<!--     return d => scale(scaleByCategory(categoryByName.get(d.name))); -->\n<!--   } -->\n<!--   return (d, i) => scale(i); -->\n<!-- } -->\n\n<!-- x = d3.scaleLinear([0, 1], [margin.left, width - margin.right]) -->\nx = d3.scaleLinear([0, 1], [margin.left,  width - margin.right])\n\ny = d3.scaleBand()\n    .domain(d3.range(n + 1))\n    .rangeRound([margin.top, margin.top + barSize * (n + 1 + 0.1)])\n    .padding(0.1)\n    \nheight = margin.top + barSize * n + margin.bottom\n\nbarSize = 48\n\nmargin = ({top: 16, right: 6, bottom: 6, left: 0})\n\nd3 = require(\"d3@6\")\n\n```\n\n\nThis visualization presents the dynamic monthly changes in COVID-19 death cases from 2020 to 2023 in each state across the United States. By showcasing the data in a ranked format, it provides an intuitive way to understand the shifts in state rankings as the pandemic progressed. This visualization helps to identify states with the highest death tolls at different points in time.\n\n## Interactive Network Chart for Ages and Conditions\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport csv\nimport json\n\n# Read in the CSV file\nfilename = \"./net/filtered_by_total.csv\"\nwith open(filename, \"r\") as csvfile:\n    reader = csv.DictReader(csvfile)\n    rows = [row for row in reader if row[\"State\"] == \"United States\"]\n\n# Create nodes dictionary\nage_groups = list(set(row[\"Age Group\"] for row in rows))\ncondition_groups = list(set(row[\"Condition Group\"] for row in rows))\nnodes = [{\"id\": group, \"group\": i} for i, group in enumerate(age_groups + condition_groups)]\n\n# Create links dictionary\nmax_value = max(int(row[\"COVID-19 Deaths\"]) for row in rows)\nmin_value = min(int(row[\"COVID-19 Deaths\"]) for row in rows)\nlinks = [{\"source\": row[\"Age Group\"], \"target\": row[\"Condition Group\"], \"value\": (int(row[\"COVID-19 Deaths\"]) - min_value) / (max_value - min_value) * 100} for row in rows]\n\n# Combine nodes and links into a single dictionary\nnetwork = {\"nodes\": nodes, \"links\": links}\n\n# Write to a JSON file\nwith open(\"./net/network.json\", \"w\") as outfile:\n    json.dump(network, outfile, indent=4)\n  \n# Load the JSON data\nwith open('./net/network.json', 'r') as f:\n    data = json.load(f)\n\n# Create a dictionary to store the max values for each source\nmax_values = {}\n\n# Loop through the links to find the max value for each source\nfor link in data['links']:\n    source = link['source']\n    value = link['value']\n    if source in max_values:\n        max_values[source].append(value)\n    else:\n        max_values[source] = [value]\n\n# Loop through the links again to filter out those with values less than the top 3\nfiltered_links = []\nfor link in data['links']:\n    source = link['source']\n    value = link['value']\n    if len(max_values[source]) > 3 and value < sorted(max_values[source], reverse=True)[2]:\n        continue\n    filtered_links.append(link)\n\n# Create a new dictionary with the filtered links\nfiltered_data = {\n    'nodes': data['nodes'],\n    'links': filtered_links\n}\n\n# Save the filtered data to a new JSON file\nwith open('./net/filtered_network.json', 'w') as f:\n    json.dump(filtered_data, f, indent=4)\n    \nwith open('./net/filtered_network.json') as f:\n    data = json.load(f)\n\nnodes = []\nnew_links = []\nsources = set([link['source'] for link in data['links']])\ntargets = set([link['target'] for link in data['links']])\n\nfor node in sources.union(targets):\n    if node in sources:\n        nodes.append({\"id\": node, \"group\": 0})\n    else:\n        for source in sources:\n            new_node_id = f\"{node}({source})\"\n            nodes.append({\"id\": new_node_id, \"group\": 1})\n            for link in data['links']:\n                if link['source'] == source and link['target'] == node:\n                    new_links.append({\"source\": source, \"target\": new_node_id, \"value\": link['value']})\n\nnew_data = {\"nodes\": nodes, \"links\": new_links}\n\nwith open('./net/new_filtered_network.json', 'w') as f:\n    json.dump(new_data, f, indent=4)\n    \n# Load the JSON file\nwith open(\"./net/new_filtered_network.json\") as f:\n    data = json.load(f)\n\n# Find all nodes in group 0\ngroup0_nodes = [node for node in data['nodes'] if node['group'] == 0]\n\n# Create a center node\ncenter_node = {'id': 'center', 'group': -1}\n\n# Add links from center node to all group 0 nodes\nlinks = data['links']\nfor node in group0_nodes:\n    links.append({'source': 'center', 'target': node['id'], 'value': 1})\n\n# Add the center node to the nodes list\nnodes = data['nodes']\nnodes.append(center_node)\n\n# Save the modified data as a new JSON file\nnew_data = {'nodes': nodes, 'links': links}\nwith open(\"./net/new_filtered_network_with_center.json\", \"w\") as f:\n    json.dump(new_data, f)\n```\n:::\n\n\nThis visualization necessitated substantial data cleansing efforts, such as generating node and link JSON files and trimming extraneous links to display only the top 3 relevant connections. Since the network visualization does not account for directional connections, it can create cross-linked nodes, resulting in a nested graph. To achieve a more visually explicit appearance, I manually duplicated the node of conditions. Furthermore, the nodes tend to gradually fade away from the screen, so incorporating a central node is essential to maintain their positions within the visualization.\n\n\n\n```{ojs}\nchart2 = ForceGraph(miserables, {\n  nodeId: d => d.id,\n  nodeGroup: d => d.group,\n  nodeTitle: d => `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l => Math.sqrt(l.value),\n  width,\n  height: 600,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n```\n\n```{ojs}\nmiserables = FileAttachment(\"./net/new_filtered_network_with_center.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d => d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) => source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) => target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) => N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) => ({id: N[i]}));\n  links = d3.map(links, (_, i) => ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) => N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation))\n    .join(\"text\")\n    .attr(\"dx\", \".10em\")\n    .attr(\"dy\", \".10em\")\n    .text(function(d) { return d.id; });\n  \n\n  \n  <!-- var circles = node.append(\"circle\") -->\n  <!-- .attr(\"r\", nodeRadius) -->\n  <!--     .call(drag(simulation)); -->\n\n  <!-- var labels = node.append(\"text\") -->\n  <!--   .attr(\"dx\", \".10em\") -->\n  <!--   .attr(\"dy\", \".10em\") -->\n  <!--   .text(function(d) { return d.id; }); -->\n\n  <!-- node.append(\"text\") -->\n  <!-- .text(({id}) => id) // display the node id as text -->\n  <!-- .attr(\"text-anchor\", \"middle\") // center the text within the circle -->\n  <!-- .attr(\"dy\", \"0.35em\"); // adjust the vertical position of the text within the circle -->\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) => W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) => L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) => color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) => T[i]);\n  if (invalidation != null) invalidation.then(() => simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d => d.source.x)\n      .attr(\"y1\", d => d.source.y)\n      .attr(\"x2\", d => d.target.x)\n      .attr(\"y2\", d => d.target.y);\n\n    node\n      .attr(\"cx\", d => d.x)\n      .attr(\"cy\", d => d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\"\n\n```\n\nThis visualization displays an interactive network chart connecting death age groups with the conditions leading to those deaths. The chart effectively demonstrates the relationships between various factors contributing to COVID-19-related fatalities.\n\nOne limitation I encountered was the inability to add labels to the force graph. Ideally, the blue node in the center should be labeled as United States, representing the entire nation. The orange nodes represent different age groups, while the red nodes situated along the boundary indicate the top 3 conditions contributing to the deaths in each corresponding age group. The width of the links between the nodes reflects the number of death cases associated with each condition.\n\n\n## Choropleth Map for COVID-19 Deaths by State\n\nGeocoding presents a significant challenge when creating choropleth maps. In R language, the maps library can be used to match specific location names to polygons with corresponding longitudes and latitudes on a map. In my project, these name lists are stored in lowercase:\n\n\tus_map <- maps::map(\"state\", plot = FALSE, fill = TRUE) %>%\n\t  st_as_sf() %>%\n\t  rename(State = ID)\n\n\tagg_data$State <- tolower(agg_data$State)\n\tus_map$State <- tolower(us_map$State)\n\nHowever, the state values in the State column were originally stored with capital initials, causing missing data throughout the map. By modifying the code as shown above, the geocoding process can now accurately map the csv data to the choropleth's required format, successfully rendering the intended map visualization.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(dplyr)\nlibrary(maps)\nlibrary(viridis)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(\"./choropleth/state_filtered_by_total.csv\", header = TRUE, sep = \",\", stringsAsFactors = FALSE)\ncolnames(data) <- gsub(\" \", \"\", colnames(data))\n\nagg_data <- data %>%\n  group_by(State) %>%\n  summarize(Total_Deaths = sum(COVID_19_Deaths, na.rm = TRUE))\n\n\nus_map <- maps::map(\"state\", plot = FALSE, fill = TRUE) %>%\n  st_as_sf() %>%\n  rename(State = ID)\n\nagg_data$State <- tolower(agg_data$State)\nus_map$State <- tolower(us_map$State)\n\nmerged_data <- left_join(us_map, agg_data, by = \"State\")\n\nmerged_data$Total_Deaths[is.na(merged_data$Total_Deaths)] <- 0\n\ncustom_breaks <- function(limits) {\n  default_breaks <- pretty(c(0, limits[2]^0.5), n = 5)^2\n  return(default_breaks)\n}\n\nggplot(data = merged_data) +\n  geom_sf(aes(fill = Total_Deaths), color = \"white\", size = 0.2) +\n  scale_fill_viridis(option = \"magma\", trans = \"sqrt\", , direction = -1, name = \"COVID-19 Deaths\",\n                     breaks = custom_breaks,\n                     guide = guide_colorbar(title.position = \"top\", title.hjust = 0.5,\n                                            label.position = \"bottom\", label.hjust = 0.5,\n                                            barwidth = 15, barheight = 0.8)) +\n  labs(title = \"Choropleth Map: COVID-19 Deaths by State\") +\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"bottom\",\n        legend.key.height = unit(2, \"cm\"),\n        legend.title = element_text(size = 11),\n        legend.text = element_text(size = 9))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nThis Choropleth Map for COVID-19 Deaths by State effectively illustrates the spatial differences in death cases across the United States, highlighting the state-wise fatality of the pandemic. By visualizing these disparities, the map underscores the importance of understanding regional variations in public health outcomes and pandemic responses. This information is crucial for policy makers, public health officials, and researchers as they develop targeted interventions, allocate resources, and evaluate the effectiveness of various strategies in mitigating the impact of COVID-19.\n\n# Conclusion\nIn this blog, I have demonstrated a workflow for processing a public COVID-19 dataset from [Data.gov](https://data.gov/) and showcasing the data characteristics using four different visualizations.\n\nThe first visualization, a bar chart of COVID-19 death cases, straightforwardly displays the significantly higher percentage of senior victims in the pandemic. The second visualization, a dynamic bar chart, proved a bit more challenging due to my limited familiarity with JavaScript. I spent some time fixing the bar shifting issues, but there remains an unresolved issue where some states with fewer death cases have their names overlapping the y-axis and becoming invisible to the audience. A potential solution could involve applying the `x(0)` variable to shift the labels accordingly, but this adjustment might also lead to broken visualizations.\n\nThe third visualization, a force graph, did not turn out as intended. It fails to convey useful information about the dataset since I was unable to add labels to the graph. I decided to include it here because it required significant effort on my part.\n\nThe final visualization, a Choropleth Map, was relatively straightforward to create, with the main challenge being the integration of lowercase state names.\n\nThroughout the course, I have learned many powerful and effective visualization techniques that have been invaluable to me. Due to time constraints, I could not include all these techniques in this blog. I would like to extend my gratitude to Professor Barrie for the invaluable lessons.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}