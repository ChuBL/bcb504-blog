[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My First Blog",
    "section": "",
    "text": "Dubplication: Practice with Network Data\n\n\nNodes and Links and edges and vertices…\n\n\n\n\nPortfolio\n\n\nDataViz\n\n\nNetwork\n\n\niGraph\n\n\nAssignment\n\n\n\n\niGRAPH!\n\n\n\n\n\n\nApr 19, 2023\n\n\nBarrie Robison\n\n\n\n\n\n\n  \n\n\n\n\nPractice with Spatial Data\n\n\nMalaria calamari\n\n\n\n\nDataViz\n\n\nMalaria\n\n\n\n\nMalaria data maps\n\n\n\n\n\n\nApr 11, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n  \n\n\n\n\nFrom Midterms to Championships: Hopw to Build Winning Pokémon Teams\n\n\nInsightful Visualizations of Pokémon Showdown Battle Data\n\n\n\n\nAssignment\n\n\nDataViz\n\n\nSmogon\n\n\nPokémon Showdown\n\n\n\n\nZapping Through the 10,000,000 Pokémon Battles\n\n\n\n\n\n\nMar 30, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n  \n\n\n\n\nASSIGNMENT 5: Happy Hockey\n\n\nCorrections for Hockey Data Visualizations\n\n\n\n\nAssignment\n\n\nDataViz\n\n\nTables\n\n\nScatterplot\n\n\nBarplot\n\n\nPiechart\n\n\n\n\nShould I trade these draft picks for this bag of magic beans…?\n\n\n\n\n\n\nMar 7, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 4\n\n\nMarks and Channels\n\n\n\n\nAssignment\n\n\nDataViz\n\n\n\n\nA clever description that describes the stuff\n\n\n\n\n\n\nFeb 16, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 3\n\n\nData Visualization\n\n\n\n\n\n\n\n\n\nFeb 14, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 2: Your Data Ver2.0\n\n\nDescribing the dataset\n\n\n\n\n\n\n\n\n\nFeb 7, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 2: Your Data Ver1.0\n\n\nDescribing the dataset\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 2: Plain Text\n\n\nDescribing the dataset\n\n\n\n\n\n\n\n\n\nJan 26, 2023\n\n\nJiyin Zhang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/assignment-2-ver1/index.html",
    "href": "posts/assignment-2-ver1/index.html",
    "title": "Assignment 2: Your Data Ver1.0",
    "section": "",
    "text": "This dataset is generated based on the elements coexistence counts from Mindat.org database. The original data source is retrieved via Mindat API and stored in JSON format. Then after data pre-process and data cleaning steps, the retrieved data is cured and stored in CSV format. The dataset can be accessed at the Github repository, in the name of total_elements_mindat.csv.\n\n\n\n\n\n\nNote\n\n\n\nThe CSV file of dataset is a concatenated version of 72 separate spread sheets of element triplets coexistence values. Each spread sheet has 2 + 72 columns, the first column indicates the background element, which should remain the same throughout each separate sheet. The second column records the second dimension of the element triplets Then the third dimension of elements are listed by the remaining columns. The value of cell \\((i, j)\\) indicating the coexistence amount of three elements: the first two elements in \\((i, 0)\\) and \\((i, 1)\\), and the third element in \\((0, j)\\).\n\n\n\n\nThe dataset was retrieved via Mindat API as a JSON file. In the data preprocessing step, the elements information are extracted and statistically recorded in a new JSON file. Then I reorganized the data into 72 spread sheets as CSV formats."
  },
  {
    "objectID": "posts/assignment-2-ver1/index.html#importing-the-data",
    "href": "posts/assignment-2-ver1/index.html#importing-the-data",
    "title": "Assignment 2: Your Data Ver1.0",
    "section": "IMPORTING THE DATA",
    "text": "IMPORTING THE DATA\nI’m going to use the built-in read.csv package to import CSV file.\n\n\nCode\nlibrary(tidyverse)\n# result <- read.csv(file = 'total_elements_mindat.csv')\nresult <- read.csv(file = 'total_elements_mindat.csv')\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(result)\n\n\nRows: 5,184\nColumns: 74\n$ zaxis <chr> \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\",…\n$ yaxis <chr> \"H\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Na\", \"Mg\", \"Al\", \"Si\"…\n$ H     <int> 3228, 51, 66, 193, 330, 128, 3205, 141, 643, 472, 817, 1023, 524…\n$ Li    <int> 51, 51, 4, 8, 2, 0, 51, 4, 19, 6, 25, 39, 9, 1, 1, 6, 8, 0, 6, 0…\n$ Be    <int> 66, 4, 66, 3, 1, 0, 66, 1, 13, 4, 8, 31, 27, 0, 0, 4, 34, 0, 0, …\n$ B     <int> 193, 8, 3, 193, 13, 3, 192, 10, 50, 55, 52, 73, 3, 8, 24, 9, 89,…\n$ C     <int> 330, 2, 1, 13, 330, 23, 317, 12, 65, 55, 50, 46, 17, 30, 19, 11,…\n$ N     <int> 128, 0, 0, 3, 23, 128, 118, 5, 23, 13, 22, 10, 18, 48, 23, 6, 8,…\n$ O     <int> 3205, 51, 66, 192, 317, 118, 3205, 138, 643, 472, 817, 1021, 524…\n$ F     <int> 141, 4, 1, 10, 12, 5, 138, 141, 54, 22, 79, 58, 30, 24, 8, 14, 5…\n$ Na    <int> 643, 19, 13, 50, 65, 23, 643, 54, 643, 106, 182, 356, 89, 102, 3…\n$ Mg    <int> 472, 6, 4, 55, 55, 13, 472, 22, 106, 472, 147, 161, 86, 61, 28, …\n$ Al    <int> 817, 25, 8, 52, 50, 22, 817, 79, 182, 147, 817, 401, 169, 135, 3…\n$ Si    <int> 1023, 39, 31, 73, 46, 10, 1021, 58, 356, 161, 401, 1023, 15, 36,…\n$ P     <int> 524, 9, 27, 3, 17, 18, 524, 30, 89, 86, 169, 15, 524, 21, 1, 32,…\n$ S     <int> 531, 1, 0, 8, 30, 48, 531, 24, 102, 61, 135, 36, 21, 531, 27, 53…\n$ Cl    <int> 210, 1, 0, 24, 19, 23, 204, 8, 39, 28, 33, 36, 1, 27, 210, 26, 5…\n$ K     <int> 287, 6, 4, 9, 11, 6, 287, 14, 82, 50, 81, 162, 32, 53, 26, 287, …\n$ Ca    <int> 918, 8, 34, 89, 97, 8, 918, 58, 187, 131, 269, 424, 134, 84, 53,…\n$ Sc    <int> 8, 0, 0, 0, 0, 0, 8, 0, 1, 3, 0, 4, 3, 0, 0, 0, 5, 8, 0, 0, 0, 0…\n$ Ti    <int> 145, 6, 0, 3, 2, 0, 145, 18, 81, 11, 9, 116, 9, 2, 2, 30, 32, 0,…\n$ V     <int> 181, 0, 0, 3, 6, 8, 180, 2, 28, 24, 31, 27, 14, 12, 3, 10, 55, 0…\n$ Cr    <int> 40, 0, 0, 4, 5, 0, 40, 2, 7, 11, 4, 13, 2, 6, 3, 3, 11, 0, 1, 2,…\n$ Mn    <int> 406, 4, 9, 15, 17, 2, 406, 14, 81, 42, 70, 185, 98, 23, 17, 28, …\n$ Fe    <int> 663, 11, 9, 18, 22, 18, 663, 15, 130, 78, 136, 216, 176, 122, 32…\n$ Co    <int> 35, 0, 0, 0, 4, 1, 35, 0, 3, 0, 1, 1, 1, 12, 2, 0, 4, 0, 0, 1, 0…\n$ Ni    <int> 63, 0, 0, 0, 12, 4, 62, 0, 2, 1, 6, 7, 2, 15, 5, 1, 4, 0, 0, 2, …\n$ Cu    <int> 359, 1, 0, 4, 36, 10, 358, 6, 16, 16, 39, 29, 40, 87, 61, 16, 50…\n$ Zn    <int> 208, 0, 3, 0, 15, 1, 208, 1, 11, 16, 23, 32, 44, 46, 7, 7, 29, 0…\n$ Ga    <int> 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ge    <int> 10, 0, 0, 0, 1, 0, 10, 0, 0, 0, 3, 1, 0, 4, 0, 0, 2, 0, 0, 0, 0,…\n$ As    <int> 397, 0, 3, 2, 4, 5, 397, 3, 36, 40, 42, 17, 9, 21, 14, 12, 112, …\n$ Se    <int> 26, 0, 0, 0, 0, 0, 26, 0, 2, 1, 4, 1, 0, 3, 2, 1, 3, 0, 0, 0, 0,…\n$ Br    <int> 3, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Rb    <int> 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Sr    <int> 77, 1, 0, 9, 12, 0, 77, 6, 23, 4, 30, 30, 15, 5, 2, 4, 20, 0, 8,…\n$ Y     <int> 54, 1, 1, 2, 27, 0, 54, 5, 18, 1, 13, 21, 6, 6, 2, 2, 18, 0, 2, …\n$ Zr    <int> 70, 1, 3, 2, 9, 0, 70, 3, 56, 2, 1, 58, 9, 1, 10, 10, 31, 0, 1, …\n$ Nb    <int> 54, 0, 0, 0, 4, 0, 54, 4, 26, 4, 1, 32, 4, 1, 2, 12, 17, 0, 7, 1…\n$ Mo    <int> 49, 0, 0, 0, 0, 1, 49, 0, 6, 4, 3, 0, 6, 5, 0, 4, 9, 0, 0, 0, 0,…\n$ Ru    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Rh    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Pd    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ag    <int> 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0…\n$ Cd    <int> 12, 0, 0, 0, 0, 0, 12, 1, 0, 0, 1, 0, 2, 8, 0, 1, 0, 0, 0, 0, 0,…\n$ In    <int> 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Sn    <int> 21, 0, 2, 1, 0, 1, 20, 0, 2, 2, 2, 8, 0, 1, 2, 0, 7, 1, 0, 0, 0,…\n$ Sb    <int> 32, 0, 0, 0, 0, 0, 32, 0, 4, 2, 5, 2, 0, 10, 3, 2, 5, 0, 2, 0, 0…\n$ Te    <int> 52, 0, 0, 0, 2, 0, 52, 0, 0, 8, 1, 0, 0, 9, 7, 0, 6, 0, 0, 0, 1,…\n$ I     <int> 12, 0, 0, 0, 0, 1, 12, 0, 3, 3, 0, 0, 0, 1, 3, 2, 3, 0, 0, 0, 2,…\n$ Cs    <int> 12, 0, 1, 1, 0, 0, 12, 2, 4, 0, 2, 8, 1, 0, 0, 1, 4, 0, 2, 1, 0,…\n$ Ba    <int> 134, 2, 3, 4, 12, 0, 134, 16, 42, 11, 34, 76, 32, 5, 9, 8, 18, 1…\n$ La    <int> 29, 0, 0, 0, 7, 0, 29, 0, 3, 1, 14, 15, 3, 0, 0, 0, 10, 0, 1, 1,…\n$ Ce    <int> 77, 0, 2, 5, 16, 0, 77, 8, 17, 10, 25, 47, 8, 4, 1, 1, 28, 0, 13…\n$ Nd    <int> 19, 0, 1, 0, 8, 0, 19, 1, 1, 0, 3, 5, 3, 2, 0, 0, 5, 0, 0, 0, 0,…\n$ Sm    <int> 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Gd    <int> 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Dy    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Er    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Yb    <int> 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Hf    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ta    <int> 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ W     <int> 22, 0, 0, 0, 1, 0, 22, 0, 5, 1, 2, 3, 1, 0, 0, 0, 7, 0, 0, 1, 0,…\n$ Re    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Os    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ir    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Pt    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Au    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Hg    <int> 11, 0, 0, 0, 3, 4, 10, 0, 0, 0, 1, 0, 1, 1, 4, 0, 0, 0, 0, 0, 0,…\n$ Tl    <int> 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 4, 2, 2, 0, 0, 0, 2, 0, 0…\n$ Pb    <int> 229, 0, 1, 5, 28, 3, 228, 6, 3, 7, 27, 32, 27, 54, 39, 3, 13, 0,…\n$ Bi    <int> 42, 0, 0, 0, 0, 2, 41, 0, 1, 1, 1, 1, 11, 4, 1, 0, 1, 0, 0, 5, 1…\n$ Th    <int> 15, 0, 0, 1, 2, 0, 15, 2, 2, 0, 2, 4, 5, 0, 0, 1, 3, 0, 1, 0, 0,…\n$ U     <int> 272, 1, 0, 0, 41, 12, 272, 8, 33, 24, 21, 20, 51, 61, 2, 27, 54,…"
  },
  {
    "objectID": "posts/assignment-2-ver1/index.html#describe-the-data",
    "href": "posts/assignment-2-ver1/index.html#describe-the-data",
    "title": "Assignment 2: Your Data Ver1.0",
    "section": "DESCRIBE THE DATA",
    "text": "DESCRIBE THE DATA\n\nData Set Type\nThe dataset is stored as a great Flat Table, the items are arranged as each of the 72 elements, with the attributes of element triplets coexistence in the cells of corresponding sheets.\n\n\nElement list\nc('H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Cs', 'Ba', 'La', 'Ce', 'Nd', 'Sm', 'Gd', 'Dy', 'Er', 'Yb', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'U')\n\n\n [1] \"H\"  \"Li\" \"Be\" \"B\"  \"C\"  \"N\"  \"O\"  \"F\"  \"Na\" \"Mg\" \"Al\" \"Si\" \"P\"  \"S\"  \"Cl\"\n[16] \"K\"  \"Ca\" \"Sc\" \"Ti\" \"V\"  \"Cr\" \"Mn\" \"Fe\" \"Co\" \"Ni\" \"Cu\" \"Zn\" \"Ga\" \"Ge\" \"As\"\n[31] \"Se\" \"Br\" \"Rb\" \"Sr\" \"Y\"  \"Zr\" \"Nb\" \"Mo\" \"Ru\" \"Rh\" \"Pd\" \"Ag\" \"Cd\" \"In\" \"Sn\"\n[46] \"Sb\" \"Te\" \"I\"  \"Cs\" \"Ba\" \"La\" \"Ce\" \"Nd\" \"Sm\" \"Gd\" \"Dy\" \"Er\" \"Yb\" \"Hf\" \"Ta\"\n[61] \"W\"  \"Re\" \"Os\" \"Ir\" \"Pt\" \"Au\" \"Hg\" \"Tl\" \"Pb\" \"Bi\" \"Th\" \"U\" \n\n\n\n\nAttribute Types\nThe attributes of the data are recorded in a 2-dimensional format, therefore the data frame rows will looks similar to the result of glimpse function.\n\n\nCode\nhead(result)\n\n\n  zaxis yaxis    H Li Be   B   C   N    O   F  Na  Mg  Al   Si   P   S  Cl   K\n1     H     H 3228 51 66 193 330 128 3205 141 643 472 817 1023 524 531 210 287\n2     H    Li   51 51  4   8   2   0   51   4  19   6  25   39   9   1   1   6\n3     H    Be   66  4 66   3   1   0   66   1  13   4   8   31  27   0   0   4\n4     H     B  193  8  3 193  13   3  192  10  50  55  52   73   3   8  24   9\n5     H     C  330  2  1  13 330  23  317  12  65  55  50   46  17  30  19  11\n6     H     N  128  0  0   3  23 128  118   5  23  13  22   10  18  48  23   6\n   Ca Sc  Ti   V Cr  Mn  Fe Co Ni  Cu  Zn Ga Ge  As Se Br Rb Sr  Y Zr Nb Mo Ru\n1 918  8 145 181 40 406 663 35 63 359 208  4 10 397 26  3  1 77 54 70 54 49  0\n2   8  0   6   0  0   4  11  0  0   1   0  0  0   0  0  0  0  1  1  1  0  0  0\n3  34  0   0   0  0   9   9  0  0   0   3  0  0   3  0  0  0  0  1  3  0  0  0\n4  89  0   3   3  4  15  18  0  0   4   0  0  0   2  0  0  1  9  2  2  0  0  0\n5  97  0   2   6  5  17  22  4 12  36  15  0  1   4  0  0  0 12 27  9  4  0  0\n6   8  0   0   8  0   2  18  1  4  10   1  0  0   5  0  1  0  0  0  0  0  1  0\n  Rh Pd Ag Cd In Sn Sb Te  I Cs  Ba La Ce Nd Sm Gd Dy Er Yb Hf Ta  W Re Os Ir\n1  0  0  3 12  2 21 32 52 12 12 134 29 77 19  1  1  0  0  1  0  5 22  0  0  0\n2  0  0  0  0  0  0  0  0  0  0   2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n3  0  0  0  0  0  2  0  0  0  1   3  0  2  1  0  0  0  0  1  0  0  0  0  0  0\n4  0  0  0  0  0  1  0  0  0  1   4  0  5  0  0  0  0  0  0  0  0  0  0  0  0\n5  0  0  0  0  0  0  0  2  0  0  12  7 16  8  0  1  0  0  0  0  0  1  0  0  0\n6  0  0  0  0  0  1  0  0  1  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  Pt Au Hg Tl  Pb Bi Th   U\n1  0  0 11  7 229 42 15 272\n2  0  0  0  0   0  0  0   1\n3  0  0  0  0   1  0  0   0\n4  0  0  0  0   5  0  1   0\n5  0  0  3  0  28  0  2  41\n6  0  0  4  0   3  2  0  12"
  },
  {
    "objectID": "posts/assignment-2-ver1/index.html#question",
    "href": "posts/assignment-2-ver1/index.html#question",
    "title": "Assignment 2: Your Data Ver1.0",
    "section": "Question",
    "text": "Question\n\n\n\n\n\n\nNote\n\n\n\n\nI have no idea why the render result of this .qmd file failed to adapt to the html style.\n\nThe problem is that the .qmd file shall not consist of the hashtag # symbol."
  },
  {
    "objectID": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html",
    "href": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html",
    "title": "Assignment 2: Plain Text",
    "section": "",
    "text": "This dataset is generated based on the elements coexistence counts from Mindat.org database. The original data source is retrieved via Mindat API and stored in JSON format. Then after data pre-process and data cleaning steps, the retrieved data is cured and stored in CSV format. The dataset can be accessed at the Github repository, in the name of total_elements_mindat.csv.\n\n\n\n\n\n\nNote\n\n\n\nThe CSV file of dataset is a concatenated version of 72 separate spread sheets of element triplets coexistence values. Each spread sheet has 2 + 72 columns, the first column indicates the background element, which should remain the same throughout each separate sheet. The second column records the second dimension of the element triplets Then the third dimension of elements are listed by the remaining columns. The value of cell \\((i, j)\\) indicating the coexistence amount of three elements: the first two elements in \\((i, 0)\\) and \\((i, 1)\\), and the third element in \\((0, j)\\).\n\n\n\n\nThe dataset was retrieved via Mindat API as a JSON file. In the data preprocessing step, the elements information are extracted and statistically recorded in a new JSON file. Then I reorganized the data into 72 spread sheets as CSV formats."
  },
  {
    "objectID": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#importing-the-data",
    "href": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#importing-the-data",
    "title": "Assignment 2: Plain Text",
    "section": "IMPORTING THE DATA",
    "text": "IMPORTING THE DATA\nI’m going to use the built-in read.csv package to import CSV file.\n\n\nCode\nlibrary(tidyverse)\nresult <- read.csv(file = 'total_elements_mindat.csv')\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(result)\n\n\nRows: 5,184\nColumns: 74\n$ zaxis <chr> \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\",…\n$ yaxis <chr> \"H\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Na\", \"Mg\", \"Al\", \"Si\"…\n$ H     <int> 3228, 51, 66, 193, 330, 128, 3205, 141, 643, 472, 817, 1023, 524…\n$ Li    <int> 51, 51, 4, 8, 2, 0, 51, 4, 19, 6, 25, 39, 9, 1, 1, 6, 8, 0, 6, 0…\n$ Be    <int> 66, 4, 66, 3, 1, 0, 66, 1, 13, 4, 8, 31, 27, 0, 0, 4, 34, 0, 0, …\n$ B     <int> 193, 8, 3, 193, 13, 3, 192, 10, 50, 55, 52, 73, 3, 8, 24, 9, 89,…\n$ C     <int> 330, 2, 1, 13, 330, 23, 317, 12, 65, 55, 50, 46, 17, 30, 19, 11,…\n$ N     <int> 128, 0, 0, 3, 23, 128, 118, 5, 23, 13, 22, 10, 18, 48, 23, 6, 8,…\n$ O     <int> 3205, 51, 66, 192, 317, 118, 3205, 138, 643, 472, 817, 1021, 524…\n$ F     <int> 141, 4, 1, 10, 12, 5, 138, 141, 54, 22, 79, 58, 30, 24, 8, 14, 5…\n$ Na    <int> 643, 19, 13, 50, 65, 23, 643, 54, 643, 106, 182, 356, 89, 102, 3…\n$ Mg    <int> 472, 6, 4, 55, 55, 13, 472, 22, 106, 472, 147, 161, 86, 61, 28, …\n$ Al    <int> 817, 25, 8, 52, 50, 22, 817, 79, 182, 147, 817, 401, 169, 135, 3…\n$ Si    <int> 1023, 39, 31, 73, 46, 10, 1021, 58, 356, 161, 401, 1023, 15, 36,…\n$ P     <int> 524, 9, 27, 3, 17, 18, 524, 30, 89, 86, 169, 15, 524, 21, 1, 32,…\n$ S     <int> 531, 1, 0, 8, 30, 48, 531, 24, 102, 61, 135, 36, 21, 531, 27, 53…\n$ Cl    <int> 210, 1, 0, 24, 19, 23, 204, 8, 39, 28, 33, 36, 1, 27, 210, 26, 5…\n$ K     <int> 287, 6, 4, 9, 11, 6, 287, 14, 82, 50, 81, 162, 32, 53, 26, 287, …\n$ Ca    <int> 918, 8, 34, 89, 97, 8, 918, 58, 187, 131, 269, 424, 134, 84, 53,…\n$ Sc    <int> 8, 0, 0, 0, 0, 0, 8, 0, 1, 3, 0, 4, 3, 0, 0, 0, 5, 8, 0, 0, 0, 0…\n$ Ti    <int> 145, 6, 0, 3, 2, 0, 145, 18, 81, 11, 9, 116, 9, 2, 2, 30, 32, 0,…\n$ V     <int> 181, 0, 0, 3, 6, 8, 180, 2, 28, 24, 31, 27, 14, 12, 3, 10, 55, 0…\n$ Cr    <int> 40, 0, 0, 4, 5, 0, 40, 2, 7, 11, 4, 13, 2, 6, 3, 3, 11, 0, 1, 2,…\n$ Mn    <int> 406, 4, 9, 15, 17, 2, 406, 14, 81, 42, 70, 185, 98, 23, 17, 28, …\n$ Fe    <int> 663, 11, 9, 18, 22, 18, 663, 15, 130, 78, 136, 216, 176, 122, 32…\n$ Co    <int> 35, 0, 0, 0, 4, 1, 35, 0, 3, 0, 1, 1, 1, 12, 2, 0, 4, 0, 0, 1, 0…\n$ Ni    <int> 63, 0, 0, 0, 12, 4, 62, 0, 2, 1, 6, 7, 2, 15, 5, 1, 4, 0, 0, 2, …\n$ Cu    <int> 359, 1, 0, 4, 36, 10, 358, 6, 16, 16, 39, 29, 40, 87, 61, 16, 50…\n$ Zn    <int> 208, 0, 3, 0, 15, 1, 208, 1, 11, 16, 23, 32, 44, 46, 7, 7, 29, 0…\n$ Ga    <int> 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ge    <int> 10, 0, 0, 0, 1, 0, 10, 0, 0, 0, 3, 1, 0, 4, 0, 0, 2, 0, 0, 0, 0,…\n$ As    <int> 397, 0, 3, 2, 4, 5, 397, 3, 36, 40, 42, 17, 9, 21, 14, 12, 112, …\n$ Se    <int> 26, 0, 0, 0, 0, 0, 26, 0, 2, 1, 4, 1, 0, 3, 2, 1, 3, 0, 0, 0, 0,…\n$ Br    <int> 3, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Rb    <int> 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Sr    <int> 77, 1, 0, 9, 12, 0, 77, 6, 23, 4, 30, 30, 15, 5, 2, 4, 20, 0, 8,…\n$ Y     <int> 54, 1, 1, 2, 27, 0, 54, 5, 18, 1, 13, 21, 6, 6, 2, 2, 18, 0, 2, …\n$ Zr    <int> 70, 1, 3, 2, 9, 0, 70, 3, 56, 2, 1, 58, 9, 1, 10, 10, 31, 0, 1, …\n$ Nb    <int> 54, 0, 0, 0, 4, 0, 54, 4, 26, 4, 1, 32, 4, 1, 2, 12, 17, 0, 7, 1…\n$ Mo    <int> 49, 0, 0, 0, 0, 1, 49, 0, 6, 4, 3, 0, 6, 5, 0, 4, 9, 0, 0, 0, 0,…\n$ Ru    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Rh    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Pd    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ag    <int> 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0…\n$ Cd    <int> 12, 0, 0, 0, 0, 0, 12, 1, 0, 0, 1, 0, 2, 8, 0, 1, 0, 0, 0, 0, 0,…\n$ In    <int> 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Sn    <int> 21, 0, 2, 1, 0, 1, 20, 0, 2, 2, 2, 8, 0, 1, 2, 0, 7, 1, 0, 0, 0,…\n$ Sb    <int> 32, 0, 0, 0, 0, 0, 32, 0, 4, 2, 5, 2, 0, 10, 3, 2, 5, 0, 2, 0, 0…\n$ Te    <int> 52, 0, 0, 0, 2, 0, 52, 0, 0, 8, 1, 0, 0, 9, 7, 0, 6, 0, 0, 0, 1,…\n$ I     <int> 12, 0, 0, 0, 0, 1, 12, 0, 3, 3, 0, 0, 0, 1, 3, 2, 3, 0, 0, 0, 2,…\n$ Cs    <int> 12, 0, 1, 1, 0, 0, 12, 2, 4, 0, 2, 8, 1, 0, 0, 1, 4, 0, 2, 1, 0,…\n$ Ba    <int> 134, 2, 3, 4, 12, 0, 134, 16, 42, 11, 34, 76, 32, 5, 9, 8, 18, 1…\n$ La    <int> 29, 0, 0, 0, 7, 0, 29, 0, 3, 1, 14, 15, 3, 0, 0, 0, 10, 0, 1, 1,…\n$ Ce    <int> 77, 0, 2, 5, 16, 0, 77, 8, 17, 10, 25, 47, 8, 4, 1, 1, 28, 0, 13…\n$ Nd    <int> 19, 0, 1, 0, 8, 0, 19, 1, 1, 0, 3, 5, 3, 2, 0, 0, 5, 0, 0, 0, 0,…\n$ Sm    <int> 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Gd    <int> 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Dy    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Er    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Yb    <int> 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Hf    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ta    <int> 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ W     <int> 22, 0, 0, 0, 1, 0, 22, 0, 5, 1, 2, 3, 1, 0, 0, 0, 7, 0, 0, 1, 0,…\n$ Re    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Os    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ir    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Pt    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Au    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Hg    <int> 11, 0, 0, 0, 3, 4, 10, 0, 0, 0, 1, 0, 1, 1, 4, 0, 0, 0, 0, 0, 0,…\n$ Tl    <int> 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 4, 2, 2, 0, 0, 0, 2, 0, 0…\n$ Pb    <int> 229, 0, 1, 5, 28, 3, 228, 6, 3, 7, 27, 32, 27, 54, 39, 3, 13, 0,…\n$ Bi    <int> 42, 0, 0, 0, 0, 2, 41, 0, 1, 1, 1, 1, 11, 4, 1, 0, 1, 0, 0, 5, 1…\n$ Th    <int> 15, 0, 0, 1, 2, 0, 15, 2, 2, 0, 2, 4, 5, 0, 0, 1, 3, 0, 1, 0, 0,…\n$ U     <int> 272, 1, 0, 0, 41, 12, 272, 8, 33, 24, 21, 20, 51, 61, 2, 27, 54,…"
  },
  {
    "objectID": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#describe-the-data",
    "href": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#describe-the-data",
    "title": "Assignment 2: Plain Text",
    "section": "DESCRIBE THE DATA",
    "text": "DESCRIBE THE DATA\n\nData Set Type\nThe dataset is stored as a great Flat Table, the items are arranged as each of the 72 elements, with the attributes of element triplets coexistence in the cells of corresponding sheets.\n\n\nElement list\nc('H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Cs', 'Ba', 'La', 'Ce', 'Nd', 'Sm', 'Gd', 'Dy', 'Er', 'Yb', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'U')\n\n\n [1] \"H\"  \"Li\" \"Be\" \"B\"  \"C\"  \"N\"  \"O\"  \"F\"  \"Na\" \"Mg\" \"Al\" \"Si\" \"P\"  \"S\"  \"Cl\"\n[16] \"K\"  \"Ca\" \"Sc\" \"Ti\" \"V\"  \"Cr\" \"Mn\" \"Fe\" \"Co\" \"Ni\" \"Cu\" \"Zn\" \"Ga\" \"Ge\" \"As\"\n[31] \"Se\" \"Br\" \"Rb\" \"Sr\" \"Y\"  \"Zr\" \"Nb\" \"Mo\" \"Ru\" \"Rh\" \"Pd\" \"Ag\" \"Cd\" \"In\" \"Sn\"\n[46] \"Sb\" \"Te\" \"I\"  \"Cs\" \"Ba\" \"La\" \"Ce\" \"Nd\" \"Sm\" \"Gd\" \"Dy\" \"Er\" \"Yb\" \"Hf\" \"Ta\"\n[61] \"W\"  \"Re\" \"Os\" \"Ir\" \"Pt\" \"Au\" \"Hg\" \"Tl\" \"Pb\" \"Bi\" \"Th\" \"U\" \n\n\n\n\nAttribute Types\nThe attributes of the data are recorded in a 2-dimensional format, therefore the data frame rows will looks similar to the result of glimpse function.\n\n\nCode\nhead(result)\n\n\n  zaxis yaxis    H Li Be   B   C   N    O   F  Na  Mg  Al   Si   P   S  Cl   K\n1     H     H 3228 51 66 193 330 128 3205 141 643 472 817 1023 524 531 210 287\n2     H    Li   51 51  4   8   2   0   51   4  19   6  25   39   9   1   1   6\n3     H    Be   66  4 66   3   1   0   66   1  13   4   8   31  27   0   0   4\n4     H     B  193  8  3 193  13   3  192  10  50  55  52   73   3   8  24   9\n5     H     C  330  2  1  13 330  23  317  12  65  55  50   46  17  30  19  11\n6     H     N  128  0  0   3  23 128  118   5  23  13  22   10  18  48  23   6\n   Ca Sc  Ti   V Cr  Mn  Fe Co Ni  Cu  Zn Ga Ge  As Se Br Rb Sr  Y Zr Nb Mo Ru\n1 918  8 145 181 40 406 663 35 63 359 208  4 10 397 26  3  1 77 54 70 54 49  0\n2   8  0   6   0  0   4  11  0  0   1   0  0  0   0  0  0  0  1  1  1  0  0  0\n3  34  0   0   0  0   9   9  0  0   0   3  0  0   3  0  0  0  0  1  3  0  0  0\n4  89  0   3   3  4  15  18  0  0   4   0  0  0   2  0  0  1  9  2  2  0  0  0\n5  97  0   2   6  5  17  22  4 12  36  15  0  1   4  0  0  0 12 27  9  4  0  0\n6   8  0   0   8  0   2  18  1  4  10   1  0  0   5  0  1  0  0  0  0  0  1  0\n  Rh Pd Ag Cd In Sn Sb Te  I Cs  Ba La Ce Nd Sm Gd Dy Er Yb Hf Ta  W Re Os Ir\n1  0  0  3 12  2 21 32 52 12 12 134 29 77 19  1  1  0  0  1  0  5 22  0  0  0\n2  0  0  0  0  0  0  0  0  0  0   2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n3  0  0  0  0  0  2  0  0  0  1   3  0  2  1  0  0  0  0  1  0  0  0  0  0  0\n4  0  0  0  0  0  1  0  0  0  1   4  0  5  0  0  0  0  0  0  0  0  0  0  0  0\n5  0  0  0  0  0  0  0  2  0  0  12  7 16  8  0  1  0  0  0  0  0  1  0  0  0\n6  0  0  0  0  0  1  0  0  1  0   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n  Pt Au Hg Tl  Pb Bi Th   U\n1  0  0 11  7 229 42 15 272\n2  0  0  0  0   0  0  0   1\n3  0  0  0  0   1  0  0   0\n4  0  0  0  0   5  0  1   0\n5  0  0  3  0  28  0  2  41\n6  0  0  4  0   3  2  0  12"
  },
  {
    "objectID": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#question",
    "href": "posts/Poor-Assignment-2-in-plain-text/Assignment#2.html#question",
    "title": "Assignment 2: Plain Text",
    "section": "Question",
    "text": "Question\n\n\n\n\n\n\nNote\n\n\n\nI have no idea why the render result of this .qmd file failed to adapt to the html style."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/assignment-2-ver2/index.html",
    "href": "posts/assignment-2-ver2/index.html",
    "title": "Assignment 2: Your Data Ver2.0",
    "section": "",
    "text": "This dataset is generated based on the elements coexistence counts from Mindat.org database. The original data source is retrieved via Mindat API and stored in JSON format. Then after data pre-process and data cleaning steps, the retrieved data is cured and stored in CSV format. The dataset can be accessed at the Github repository, in the name of mineral.csv.\n\n\n\n\n\nThe dataset was retrieved via Mindat API as a JSON file. In the data preprocessing step, the elements information are extracted in a new JSON file, in which some of the hierarchical structures have been removed in convenience of python’s to_csv function. Then the exported csv file can be read directly with R’s read.csv function."
  },
  {
    "objectID": "posts/assignment-2-ver2/index.html#importing-the-data",
    "href": "posts/assignment-2-ver2/index.html#importing-the-data",
    "title": "Assignment 2: Your Data Ver2.0",
    "section": "IMPORTING THE DATA",
    "text": "IMPORTING THE DATA\nI’m going to use the built-in read.csv package to import CSV file.\n\n\nCode\nlibrary(tidyverse)\n# result <- read.csv(file = 'total_elements_mindat.csv')\nresult <- read.csv(file = 'mineral.csv')\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(result)\n\n\nRows: 5,883\nColumns: 17\n$ id              <int> 1, 2, 3, 4, 9, 10, 13, 14, 18, 19, 21, 23, 27, 31, 32,…\n$ name            <chr> \"Abelsonite\", \"Abenakiite-(Ce)\", \"Abernathyite\", \"Abhu…\n$ elements        <chr> \"-Ni-N-C-H-\", \"-Ce-Na-Si-O-P-C-S-\", \"-As-O-K-H-U-\", \"-…\n$ sigelements     <chr> \"-Ni-N-C-H-\", \"-Ce-Na-Si-O-P-C-S-\", \"-As-O-K-H-U-\", \"-…\n$ yeardiscovery   <chr> \"1975\", \"\", \"1956\", \"1983\", \"1990\", \"1855\", \"1974\", \"1…\n$ hmin            <dbl> 2.0, 4.0, 2.5, 2.0, 6.5, 2.0, 1.0, 2.5, 5.0, 3.5, 3.5,…\n$ hmax            <dbl> 3.0, 5.0, 3.0, 2.0, 6.5, 2.5, 1.5, 2.5, 6.0, 3.5, 3.5,…\n$ hardtype        <int> 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, …\n$ specificgravity <chr> \"1.4\", \"3.21\", \"\", \"4.29\", \"\", \"7.24 (calc)  7.2-7.4(m…\n$ strunz10ed1     <int> 10, 9, 8, 3, 9, 2, 10, 2, 9, 3, 8, 8, 6, 9, 9, 9, 9, 8…\n$ strunz10ed2     <chr> \"C\", \"C\", \"E\", \"D\", \"A\", \"B\", \"A\", \"C\", \"D\", \"C\", \"B\",…\n$ strunz10ed3     <chr> \"A\", \"K\", \"B\", \"A\", \"G\", \"A\", \"A\", \"C\", \"E\", \"C\", \"B\",…\n$ strunz10ed4     <chr> \"20\", \"10\", \"15\", \"30\", \"05\", \"35\", \"20\", \"05\", \"10\", …\n$ dana8ed1        <chr> \"50\", \"61\", \"40\", \"10\", \"7\", \"2\", \"50\", \"0\", \"0\", \"11\"…\n$ dana8ed2        <chr> \"4\", \"4\", \"2a\", \"5\", \"5\", \"4\", \"4\", \"0\", \"0\", \"6\", \"6\"…\n$ dana8ed3        <chr> \"9\", \"1\", \"9\", \"9\", \"1\", \"1\", \"7\", \"0\", \"0\", \"17\", \"6\"…\n$ dana8ed4        <chr> \"1\", \"1\", \"1\", \"1\", \"4\", \"1\", \"1\", \"0\", \"0\", \"1\", \"3\",…"
  },
  {
    "objectID": "posts/assignment-2-ver2/index.html#describe-the-data",
    "href": "posts/assignment-2-ver2/index.html#describe-the-data",
    "title": "Assignment 2: Your Data Ver2.0",
    "section": "DESCRIBE THE DATA",
    "text": "DESCRIBE THE DATA\n\nData Set Type\nThe dataset is stored as a great Flat Table, the items are 5883 mineral species from OpenMindat data server, and the columns representing the corresponding attributes.\n\n\nMineral Species Attributes\nc('id', 'name', 'elements', 'sigelements', 'yeardiscovery', 'hmin', 'hmax', 'hardtype', 'specificgravity', 'strunz10ed1', 'strunz10ed2', 'strunz10ed3', 'strunz10ed4', 'dana8ed1', 'dana8ed2', 'dana8ed3', 'dana8ed4')\n\n\n [1] \"id\"              \"name\"            \"elements\"        \"sigelements\"    \n [5] \"yeardiscovery\"   \"hmin\"            \"hmax\"            \"hardtype\"       \n [9] \"specificgravity\" \"strunz10ed1\"     \"strunz10ed2\"     \"strunz10ed3\"    \n[13] \"strunz10ed4\"     \"dana8ed1\"        \"dana8ed2\"        \"dana8ed3\"       \n[17] \"dana8ed4\"       \n\n\n\n\nAttribute Types\nThe attributes of the data are recorded in a 2-dimensional format, therefore the data frame rows will looks similar to the result of glimpse function. The ‘id’ field is in a strict ascending order, while not continuous. The ‘id’ field of each row is determined by the website managers or data providers, therefore it has nothing to do with some standard identifications. The ‘names’ field indicates the IMA approved mineral species names. The ‘elements’ and ‘sigelements’ fields indicating the elements of the mineral chemical formual, while the ‘sigelement’ is determined by some significant elements as a subset of ‘elements’. In compatable with csv format, the elements in this field are separated by hyphens \\(-\\).\n\n\nCode\nhead(result)\n\n\n  id            name           elements        sigelements yeardiscovery hmin\n1  1      Abelsonite         -Ni-N-C-H-         -Ni-N-C-H-          1975  2.0\n2  2 Abenakiite-(Ce) -Ce-Na-Si-O-P-C-S- -Ce-Na-Si-O-P-C-S-                4.0\n3  3    Abernathyite       -As-O-K-H-U-       -As-O-K-H-U-          1956  2.5\n4  4        Abhurite        -Cl-Sn-O-H-        -Cl-Sn-O-H-          1983  2.0\n5  9  Abswurmbachite       -Cu-Mn-Si-O-       -Cu-Mn-Si-O-          1990  6.5\n6 10       Acanthite             -Ag-S-             -Ag-S-          1855  2.0\n  hmax hardtype            specificgravity strunz10ed1 strunz10ed2 strunz10ed3\n1  3.0        0                        1.4          10           C           A\n2  5.0        0                       3.21           9           C           K\n3  3.0        0                                      8           E           B\n4  2.0        3                       4.29           3           D           A\n5  6.5        0                                      9           A           G\n6  2.5        3 7.24 (calc)  7.2-7.4(meas)           2           B           A\n  strunz10ed4 dana8ed1 dana8ed2 dana8ed3 dana8ed4\n1          20       50        4        9        1\n2          10       61        4        1        1\n3          15       40       2a        9        1\n4          30       10        5        9        1\n5          05        7        5        1        4\n6          35        2        4        1        1"
  },
  {
    "objectID": "posts/assignment-2-ver2/index.html#question",
    "href": "posts/assignment-2-ver2/index.html#question",
    "title": "Assignment 2: Your Data Ver2.0",
    "section": "Question",
    "text": "Question\n\n\n\n\n\n\nNote\n\n\n\n\nI have no idea why the render result of this .qmd file failed to adapt to the html style.\n\nThe problem is that the .qmd file shall not consist of the hashtag # symbol.\nAnother issue fixed is that the json file is originally contains 5883 items, which should be converted into 5883 rows of csv items. While the converting results shows there were over 5900 rows. The reason for this problem is that there are some annoying \\ns in the attributes, which will end up with new rows in the exported csv file. I fixed this issue by simply removing all the \\ns in the json file."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Brief Description\nA Pokemon master. This is my first blog created via quarto.\n\n\nEducation Experience\nGraduated from the Primary Pokemon School of Masala Town."
  },
  {
    "objectID": "posts/assignment-2-ver2/index.html#visualization",
    "href": "posts/assignment-2-ver2/index.html#visualization",
    "title": "Assignment 2: Your Data Ver2.0",
    "section": "Visualization",
    "text": "Visualization\n\nThe correaltion between elements and hardness\n\nElements <- c('H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Cs', 'Ba', 'La', 'Ce', 'Nd', 'Sm', 'Gd', 'Dy', 'Er', 'Yb', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Th', 'U')\nlibrary(\"tidyverse\")\n\ndf <- data.frame(Elements)\ndf1 <- df %>%\n  add_column(hmin = NA, hmin_mineral = NA, hmax = NA, hmax_mineral = NA, hmean = NA)\n\n# for (row in 1:nrow(result)) {\n#     mineral_name <- result[row, \"name\"]\n#     elements <- str_extract_all(\n#       result[row, \"elements\"], regex(\"(?<=-)[A-Z]+[a-z]*(?=-)\")\n#       )\n# \n#     hmin <- result[row, \"hmin\"]\n#     for (element in elements){\n#         comparing_hmin <- df1[df1$Elements == element, 'hmin']\n#         if (is.na(comparing_hmin)){\n#           df1[df1$Elements == element, 'hmin'] <- hmin\n#         }\n#     }\n#     # hmax <- result[row, \"hmax\"]\n# }\n\nprint(df1)\n\n   Elements hmin hmin_mineral hmax hmax_mineral hmean\n1         H   NA           NA   NA           NA    NA\n2        Li   NA           NA   NA           NA    NA\n3        Be   NA           NA   NA           NA    NA\n4         B   NA           NA   NA           NA    NA\n5         C   NA           NA   NA           NA    NA\n6         N   NA           NA   NA           NA    NA\n7         O   NA           NA   NA           NA    NA\n8         F   NA           NA   NA           NA    NA\n9        Na   NA           NA   NA           NA    NA\n10       Mg   NA           NA   NA           NA    NA\n11       Al   NA           NA   NA           NA    NA\n12       Si   NA           NA   NA           NA    NA\n13        P   NA           NA   NA           NA    NA\n14        S   NA           NA   NA           NA    NA\n15       Cl   NA           NA   NA           NA    NA\n16        K   NA           NA   NA           NA    NA\n17       Ca   NA           NA   NA           NA    NA\n18       Sc   NA           NA   NA           NA    NA\n19       Ti   NA           NA   NA           NA    NA\n20        V   NA           NA   NA           NA    NA\n21       Cr   NA           NA   NA           NA    NA\n22       Mn   NA           NA   NA           NA    NA\n23       Fe   NA           NA   NA           NA    NA\n24       Co   NA           NA   NA           NA    NA\n25       Ni   NA           NA   NA           NA    NA\n26       Cu   NA           NA   NA           NA    NA\n27       Zn   NA           NA   NA           NA    NA\n28       Ga   NA           NA   NA           NA    NA\n29       Ge   NA           NA   NA           NA    NA\n30       As   NA           NA   NA           NA    NA\n31       Se   NA           NA   NA           NA    NA\n32       Br   NA           NA   NA           NA    NA\n33       Rb   NA           NA   NA           NA    NA\n34       Sr   NA           NA   NA           NA    NA\n35        Y   NA           NA   NA           NA    NA\n36       Zr   NA           NA   NA           NA    NA\n37       Nb   NA           NA   NA           NA    NA\n38       Mo   NA           NA   NA           NA    NA\n39       Ru   NA           NA   NA           NA    NA\n40       Rh   NA           NA   NA           NA    NA\n41       Pd   NA           NA   NA           NA    NA\n42       Ag   NA           NA   NA           NA    NA\n43       Cd   NA           NA   NA           NA    NA\n44       In   NA           NA   NA           NA    NA\n45       Sn   NA           NA   NA           NA    NA\n46       Sb   NA           NA   NA           NA    NA\n47       Te   NA           NA   NA           NA    NA\n48        I   NA           NA   NA           NA    NA\n49       Cs   NA           NA   NA           NA    NA\n50       Ba   NA           NA   NA           NA    NA\n51       La   NA           NA   NA           NA    NA\n52       Ce   NA           NA   NA           NA    NA\n53       Nd   NA           NA   NA           NA    NA\n54       Sm   NA           NA   NA           NA    NA\n55       Gd   NA           NA   NA           NA    NA\n56       Dy   NA           NA   NA           NA    NA\n57       Er   NA           NA   NA           NA    NA\n58       Yb   NA           NA   NA           NA    NA\n59       Hf   NA           NA   NA           NA    NA\n60       Ta   NA           NA   NA           NA    NA\n61        W   NA           NA   NA           NA    NA\n62       Re   NA           NA   NA           NA    NA\n63       Os   NA           NA   NA           NA    NA\n64       Ir   NA           NA   NA           NA    NA\n65       Pt   NA           NA   NA           NA    NA\n66       Au   NA           NA   NA           NA    NA\n67       Hg   NA           NA   NA           NA    NA\n68       Tl   NA           NA   NA           NA    NA\n69       Pb   NA           NA   NA           NA    NA\n70       Bi   NA           NA   NA           NA    NA\n71       Th   NA           NA   NA           NA    NA\n72        U   NA           NA   NA           NA    NA\n\nprint(df1[df1$Elements == 'H', 'hmin'])\n\n[1] NA\n\n\n\ncomparing_hmin <- df1[df1$Elements == 'H', 'hmin']\nprint(comparing_hmin)\n\n[1] NA\n\nif (is.na(comparing_hmin)){\n  # df1[df1$Elements == element, 'hmin'] <- hmin\n  print('hello')\n}\n\n[1] \"hello\"\n\nelements <- str_extract_all(\n      result[1, \"elements\"], regex(\"(?<=-)[A-Z]+[a-z]*(?=-)\")\n      )\nprint(elements)\n\n[[1]]\n[1] \"Ni\" \"N\"  \"C\"  \"H\" \n\n# for (element in elements){\n#   comparing_name <- df1[df1$Elements == element, 'Elements']\n#   #v comparing_hmin <- df1[df1$Elements == element, 'hmin']\n#   #print(element, sep = '\\n')\n#   print(comparing_name, sep = '\\n')\n#   #cat(comparing_hmin, sep = '\\n')\n# }\n\n\nprint(class(elements))\n\n[1] \"list\"\n\nfor (i in 1:length(elements)){\n  print(elements[i])\n  print('hello')\n  }\n\n[[1]]\n[1] \"Ni\" \"N\"  \"C\"  \"H\" \n\n[1] \"hello\"\n\nfor (element in elements){\n  print(element)\n  print('hello')\n }\n\n[1] \"Ni\" \"N\"  \"C\"  \"H\" \n[1] \"hello\"\n\n# comparing_hmin <- df1[df1$Elements == 'H', 'hmin']\n# print(comparing_hmin)\n# print(class(comparing_hmin))\n# if (is.na(comparing_hmin)){\n#   print('test')\n# }\n\n\n# x <- c('-Ce-Na-Si-O-P-C-S-')\n# y <- str_extract_all(x, regex(\"(?<=-)[A-Z]+[a-z]*(?=-)\"))\n# for (item in y){\n#   cat(item, sep=\"\\n\")\n# }\n#   \n# \n# primes_list <- list(2, 3, 5, 7, 11, 13)\n\n# # loop version 1\n# for (p in primes_list) {\n#   print(p)\n# }"
  },
  {
    "objectID": "posts/assignment-3/index.html",
    "href": "posts/assignment-3/index.html",
    "title": "Assignment 3",
    "section": "",
    "text": "This dataset is generated based on the elements coexistence counts from Mindat.org database. The original data source is retrieved via Mindat API and stored in JSON format. Then after data pre-process and data cleaning steps, the retrieved data is cured and stored in CSV format. The dataset can be accessed at the Github repository, in the name of hardness.\n\n\n\n\n\nThe dataset was retrieved via Mindat API as a JSON file. In the data preprocessing step, the elements information are extracted in a new JSON file, in which some of the hierarchical structures have been removed in convenience of python’s to_csv function. Then the exported csv file can be read directly with R’s read.csv function."
  },
  {
    "objectID": "posts/assignment-3/index.html#importing-the-data",
    "href": "posts/assignment-3/index.html#importing-the-data",
    "title": "Assignment 3",
    "section": "IMPORTING THE DATA",
    "text": "IMPORTING THE DATA\nI’m going to use the built-in read.csv package to import CSV file.\n\n\nCode\nlibrary(tidyverse)\n# result <- read.csv(file = 'total_elements_mindat.csv')\ndf_72 <- read.csv(file = 'hardness.csv')\ndf_30 <- read.csv(file = 'hardness_30.csv')\n\n\nThe glimpse command in the Tidyverse package is a nice way to summarize the data frame:\n\n\nCode\nglimpse(df_72)\n\n\nRows: 72\nColumns: 7\n$ X            <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ elements     <chr> \"H\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Na\", \"Mg\", \"Al…\n$ hmin         <dbl> 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 0.…\n$ hmin_mineral <chr> \"Rectorite\", \"Hectorite\", \"Beryllite\", \"Barberiite\", \"Ace…\n$ hmax         <dbl> 9.0, 8.0, 9.0, 10.0, 10.0, 10.0, 9.0, 8.0, 8.0, 9.0, 9.0,…\n$ hmax_mineral <chr> \"Bahianite\", \"Pezzottaite\", \"Bromellite\", \"Qingsongite\", …\n$ hmean        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "posts/assignment-3/index.html#describe-the-data",
    "href": "posts/assignment-3/index.html#describe-the-data",
    "title": "Assignment 3",
    "section": "DESCRIBE THE DATA",
    "text": "DESCRIBE THE DATA\n\nData Set Type\nThe dataset is stored as a great Flat Table, the items are 5883 mineral species from OpenMindat data server, and the columns representing the corresponding attributes.\n\n\nMineral Species Attributes\nc('elements', 'hmin', 'hmin_mineral', 'hmax', 'hmax_mineral', 'hmean')\n\n\n[1] \"elements\"     \"hmin\"         \"hmin_mineral\" \"hmax\"         \"hmax_mineral\"\n[6] \"hmean\"       \n\n\n\n\nAttribute Types\nThe attributes of the data are recorded in a 2-dimensional format, therefore the data frame rows will looks similar to the result of glimpse function. The ‘id’ field is in a strict ascending order, while not continuous. The ‘id’ field of each row is determined by the website managers or data providers, therefore it has nothing to do with some standard identifications. The ‘names’ field indicates the IMA approved mineral species names. The ‘elements’ and ‘sigelements’ fields indicating the elements of the mineral chemical formual, while the ‘sigelement’ is determined by some significant elements as a subset of ‘elements’. In compatable with csv format, the elements in this field are separated by hyphens \\(-\\).\n\n\nCode\nhead(df_72)\n\n\n  X elements hmin hmin_mineral hmax hmax_mineral hmean\n1 0        H  0.5    Rectorite    9    Bahianite    NA\n2 1       Li  1.0    Hectorite    8  Pezzottaite    NA\n3 2       Be  1.0    Beryllite    9   Bromellite    NA\n4 3        B  1.0   Barberiite   10  Qingsongite    NA\n5 4        C  1.0    Acetamide   10      Diamond    NA\n6 5        N  1.0    Acetamide   10  Qingsongite    NA\n\n\n\n\nTASK ABSTRACTION\n\nDiscover Hardness Distributions\nAmong all of the confusing hardness records in tens of elements, we want to sense the approximate hardness distribution via visualization.\n\nlibrary(ggplot2)\nggplot(df_72, aes(x=elements, y=hmax)) +\n  geom_point(size=2, shape=23)\n\n\n\n\n\nhead(df_30)\n\n  X elements hmin hmin_mineral hmax hmax_mineral hmean\n1 0        H  0.5    Rectorite    9    Bahianite    NA\n2 1        B  1.0   Barberiite   10  Qingsongite    NA\n3 2        C  1.0    Acetamide   10      Diamond    NA\n4 3        O  0.5    Rectorite    9    Bahianite    NA\n5 4        F  1.0   Barberiite    8        Topaz    NA\n6 5       Na  0.5    Rectorite    8 Diaoyudaoite    NA\n\nggplot(df_30, aes(x=elements, y=hmin)) +\n  geom_point(size=2, shape=23)\n\n\n\nggplot(df_30, aes(x=elements, y=hmax)) +\n  geom_point(size=2, shape=23)"
  },
  {
    "objectID": "posts/assignment-3/index.html#question",
    "href": "posts/assignment-3/index.html#question",
    "title": "Assignment 3",
    "section": "Question",
    "text": "Question\n\n\n\n\n\n\nNote\n\n\n\n\nI have no idea why the render result of this .qmd file failed to adapt to the html style.\n\nThe problem is that the .qmd file shall not consist of the hashtag # symbol.\nAnother issue fixed is that the json file is originally contains 5883 items, which should be converted into 5883 rows of csv items. While the converting results shows there were over 5900 rows. The reason for this problem is that there are some annoying \\ns in the attributes, which will end up with new rows in the exported csv file. I fixed this issue by simply removing all the \\ns in the json file.\n\nif condition longer than 1\nfor loop chaos\nrendering failed blocks"
  },
  {
    "objectID": "posts/assignment-4/index.html",
    "href": "posts/assignment-4/index.html",
    "title": "Assignment 4",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n# result <- read.csv(file = 'total_elements_mindat.csv')\nmineral <- read.csv(file = 'mineral.csv')\n# result <- read.csv(file = 'total_elements_mindat.csv')\n# df_72 <- read.csv(file = 'hardness.csv')\ndf_30 <- read.csv(file = 'hardness_30.csv')"
  },
  {
    "objectID": "posts/assignment-4/index.html#funny-visualization",
    "href": "posts/assignment-4/index.html#funny-visualization",
    "title": "Assignment 4",
    "section": "Funny visualization",
    "text": "Funny visualization\n\nExpressiveness and Effectiveness\n** Wrong Version:** Our main theme is about the hardness of minerals. To best demonstrate the characteristic of our elements list, I choose to visualize the index of the elements.\n\n\nCode\nhead(df_30)\n\n\n  X elements hmin hmin_mineral hmax hmax_mineral hmean\n1 0        H  0.5    Rectorite    9    Bahianite    NA\n2 1        B  1.0   Barberiite   10  Qingsongite    NA\n3 2        C  1.0    Acetamide   10      Diamond    NA\n4 3        O  0.5    Rectorite    9    Bahianite    NA\n5 4        F  1.0   Barberiite    8        Topaz    NA\n6 5       Na  0.5    Rectorite    8 Diaoyudaoite    NA\n\n\nCode\n# ggplot(df_30, aes(x=elements, y=X)) +\nggplot(df_30, aes(x=factor(elements, level=elements), y=X)) +\n  geom_point(size=2, shape=as.integer(df_30$X)) + \n  labs(title = \"Expressiveness and Effectiveness\",\n              subtitle = \"Plot of elements by shapes\",\n              caption = \"The hardness for elements\")\n\n\nWarning in grid.Call.graphics(C_points, x$x, x$y, x$pch, x$size): unimplemented\npch value '26'\n\n\nWarning in grid.Call.graphics(C_points, x$x, x$y, x$pch, x$size): unimplemented\npch value '27'\n\n\nWarning in grid.Call.graphics(C_points, x$x, x$y, x$pch, x$size): unimplemented\npch value '28'\n\n\n\n\n\n** Corrected Version:**\n\n\nCode\nhead(df_30)\n\n\n  X elements hmin hmin_mineral hmax hmax_mineral hmean\n1 0        H  0.5    Rectorite    9    Bahianite    NA\n2 1        B  1.0   Barberiite   10  Qingsongite    NA\n3 2        C  1.0    Acetamide   10      Diamond    NA\n4 3        O  0.5    Rectorite    9    Bahianite    NA\n5 4        F  1.0   Barberiite    8        Topaz    NA\n6 5       Na  0.5    Rectorite    8 Diaoyudaoite    NA\n\n\nCode\n# ggplot(df_30, aes(x=elements, y=X)) +\nggplot(df_30, aes(x=factor(elements, level=elements), y=hmax)) +\n  geom_point(size=2) + \n  labs(title = \"Expressiveness and Effectiveness\",\n              subtitle = \"Plot of element hardness by position\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\n\n\nDiscriminability\n** Wrong Version:** In terms of discriminability, we believe the larger the axis, the more details can viz to reveal.\n\n\nCode\nggplot(df_30, aes(x=elements, y=hmax)) +\n  ylim(0, 100) +\n  geom_point(size=2, shape=23) + \n  labs(title = \"Discriminability\",\n              subtitle = \"Plot of element hardness with large y-axis\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\n** Corrected Version:**\n\n\nCode\nggplot(df_30, aes(x=elements, y=hmax)) +\n  ylim(0, 10) +\n  geom_point(size=2, shape=23) + \n  labs(title = \"Discriminability\",\n              subtitle = \"Plot of element hardness with proper y-axis\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\n\n\nSeparability\n** Wrong Version:** We noticed that the values of ‘hmin’ are too small to tell, so we amplified it by applying exponential transform.\n\n\nCode\nggplot(df_30, aes(x=elements, y=exp(hmax))) +\n  geom_point(size=2, shape=23) + \n  labs(title = \"Separability\",\n              subtitle = \"Plot of element hardness with exponential transform on hmin.\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\nCode\n  #scale_y_continuous(trans='log2')\n\n\n** Corrected Version:**\n\n\nCode\nggplot(df_30, aes(x=elements, y=log(hmax))) +\n  geom_point(size=2, shape=23) + \n  labs(title = \"Separability\",\n              subtitle = \"Plot of element hardness with proper y-axis\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\nCode\n  #scale_y_continuous(trans='log2')\n\n\n\n\nPopout\nNothing can be more striking than the areas of the scatters. And guess what? We will also add some colors to make it as eye-catching as rainbow!\n\n\nCode\nggplot(df_30, aes(x=elements, y=hmax)) +\n  geom_point(size=df_30$hmax, shape=23, colour = factor(as.integer(df_30$hmax)))"
  },
  {
    "objectID": "posts/assignment-4/index.html#expressiveness-and-effectiveness",
    "href": "posts/assignment-4/index.html#expressiveness-and-effectiveness",
    "title": "Assignment 4",
    "section": "Expressiveness and Effectiveness",
    "text": "Expressiveness and Effectiveness\n\nCorrected Version\n\n\nCode\n# head(df_30)\n# # ggplot(df_30, aes(x=elements, y=X)) +\n# ggplot(df_30, aes(x=factor(elements, level=elements), y=hmax)) +\n#   geom_point(size=2) + \n#   labs(title = \"Fig 1. Expressiveness and Effectiveness\",\n#               subtitle = \"Plot of element hardness by length\",\n#               caption = \"The hardness for elements\")\n\n# head(mineral)\nggplot(mineral, aes(x=hmax)) + geom_histogram()+ \n  labs(title = \"Fig 1. The hardness distribution among minerals\",\n              subtitle = \"Channel: Length, Mark: Lines\",\n              caption = \"The hardness for elements\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\n# # Change the width of bins\n# ggplot(mineral, aes(x=hmax)) +\n#   geom_histogram(binwidth=1)\n# # Change colors\n# p<-ggplot(mineral) +\n#   geom_histogram(color=\"black\", fill=\"white\")\n# p\n\n\n\n\nWrong Version\nOur main theme is about the hardness of minerals. To best demonstrate the characteristic of our elements list, I choose to visualize the index of the elements.\n\n\nCode\n# head(df_30)\n# ggplot(df_30, aes(x=elements, y=X)) +\n# ggplot(df_30, aes(x=factor(elements, level=elements), y=X)) +\n#   geom_point(size=2, shape=as.integer(df_30$X)) + \n#   labs(title = \"Fig 2. The hardness distribution among minerals\",\n#               subtitle = \"Plot of elements by shapes\",\n#               caption = \"The hardness for elements\")\n\nggplot(df_30, aes(x=factor(elements, level=elements), y=X)) +\n  geom_point(size=2, shape=as.integer(df_30$hmax)) + \n  labs(title = \"Fig 2. The hardness distribution among elements\",\n              subtitle = \"Channel: Shape, Mark: Points\",\n              caption = \"The hardness for elements\")"
  },
  {
    "objectID": "posts/assignment-4/index.html#discriminability",
    "href": "posts/assignment-4/index.html#discriminability",
    "title": "Assignment 4",
    "section": "Discriminability",
    "text": "Discriminability\n\nCorrected Version\n\n\nCode\n#head(df_30)\n# ggplot(df_30, aes(x=elements, y=X)) +\nggplot(df_30, aes(x=factor(elements, level=elements), y=hmax)) +\n  geom_point(size=2) +\n  labs(title = \"Fig 3. The hardness distribution among elements\",\n              subtitle = \"Channel: Position, Mark: Points\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\n\n\nWrong Version\n\n\nCode\nggplot(mineral, aes(x=sigelements, y=hmax)) +\n  geom_point(size=2) +\n  labs(title = \"Fig 4. The hardness distribution among sigelements\",\n              subtitle = \"Channel: Position, Mark: Points\",\n              caption = \"The hardness for elements\")"
  },
  {
    "objectID": "posts/assignment-4/index.html#separability",
    "href": "posts/assignment-4/index.html#separability",
    "title": "Assignment 4",
    "section": "Separability",
    "text": "Separability\n\nCorrected Version\n\n\nCode\nggplot(df_30, aes(x=factor(elements, level=elements), y=hmax)) +\n  geom_point(size=2, shape=23) + \n  labs(title = \"Fig 5. Distribution of element-wised hardness\",\n              subtitle = \"Channel: Position, Mark: Points\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\nCode\n  #scale_y_continuous(trans='log2')\n\n\n\n\nWrong Version\nWe noticed that the values of ‘hmin’ are too small to tell, so we amplified it by applying exponential transform.\n\n\nCode\n# ggplot(df_30, aes(x=elements, y=hmax)) +\n#   geom_point(size=2, shape=23) + \n#   labs(title = \"Separability\",\n#               subtitle = \"Plot of element hardness with exponential transform on hmin.\",\n#               caption = \"The hardness for elements\")\n#   #scale_y_continuous(trans='log2')\n# Basic piechart\nggplot(df_30, aes(x=factor(elements, level=elements), y=hmax, fill=factor(elements, level=elements))) +\n  geom_bar(stat=\"identity\", width=1) +\n  coord_polar(\"y\", start=0) + \n  labs(title = \"Fig 6. Pie chart of element-wised hardness\",\n              subtitle = \"Channel: Color, Mark: Length\",\n              caption = \"The hardness for elements\")"
  },
  {
    "objectID": "posts/assignment-4/index.html#popout",
    "href": "posts/assignment-4/index.html#popout",
    "title": "Assignment 4",
    "section": "Popout",
    "text": "Popout\n\nCorrected Version\n\n\nCode\nggplot(df_30, aes(x=elements, y=hmax)) +\n  geom_point(size=2, shape=23, colour = factor(as.integer(df_30$hmax))) + \n  labs(title = \"Fig 7. Pie chart of element-wised hardness\",\n              subtitle = \"Channel: Position, Color, Mark: Points\",\n              caption = \"The hardness for elements\")\n\n\n\n\n\n\n\nWrong Version\nNothing can be more striking than the areas of the scatters. And guess what? We will also add some colors to make it as eye-catching as rainbow!\n\n\nCode\nggplot(df_30, aes(x=elements, y=hmax)) +\n  geom_point(size=df_30$hmax, shape=23, colour = factor(as.integer(df_30$hmax))) + \n  labs(title = \"Fig 6. Pie chart of element-wised hardness\",\n              subtitle = \"Channel: Position, Color, Mark: Points, Area\",\n              caption = \"The hardness for elements\")"
  },
  {
    "objectID": "posts/assignment-5/index.html",
    "href": "posts/assignment-5/index.html",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "",
    "text": "In this assignment, we are going to practice creating visualizations for tabular data. Unlike previous assignments, however, this time we will all be using the same data sets. I’m doing this because I want everyone to engage in the same logic process and have the same design objectives in mind."
  },
  {
    "objectID": "posts/assignment-5/index.html#scenario",
    "href": "posts/assignment-5/index.html#scenario",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "SCENARIO",
    "text": "SCENARIO\nImagine you are a high priced data science consultant. One of your good friends, Cassandra Canuck, is an Assistant General Manager for the Vancouver Canucks, a team in the National Hockey League with a long, long…. long history of futility.\nCassandra tells you her boss, General Manager Hans Doofenschmirtz, is considering trading this year’s first round draft pick for two second round picks and one third round pick from another team. For the purposes of this exercise, let’s set the 2023 NHL draft order using the Tankathon Simulator. The NHL uses a lottery system in which the teams lowest in the standings have the highest odds of getting the first overall pick. I’ll simulate the lottery now…\nHOLY CRAP! The Vancouver Canucks jump up 6 spots, and will pick FIRST overall. Here is a screenshot:\n\nOur official scenario is this:\nVancouver receives: The 7th pick in the second round (39th overall), the 10th pick in the second round (42nd overall), and the 10th pick in the third round (74th overall).\nDetroit receives: The 1st pick in the first round (1st overall).\nDoofenschmirtz reasons that more draft picks are better, and is inclined to make the trade. Cassandra isn’t so sure…\nShe asks you to create some data visualizations she can show to her boss that might help him make the best decision."
  },
  {
    "objectID": "posts/assignment-5/index.html#directions",
    "href": "posts/assignment-5/index.html#directions",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "DIRECTIONS",
    "text": "DIRECTIONS\nCreate a new post in your portfolio for this assignment. Call it something cool, like NHL draft analysis, or Hockey Analytics, or John Wick….\nCopy the data files from the repository, and maybe also the .qmd file.\nUse the .qmd file as the backbone of your assignment, changing the code and the markdown text as you go."
  },
  {
    "objectID": "posts/assignment-5/index.html#the-data",
    "href": "posts/assignment-5/index.html#the-data",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "THE DATA",
    "text": "THE DATA\nHow can we evaluate whether trading a first round pick for two second round picks and a third round pick is a good idea? One approach is to look at the historical performance of players from these draft rounds.\nI’ve created a data set that will allow us to explore player performance as a function of draft position. If you are curious as to how I obtained and re-arranged these data, you can check out that tutorial here. For this assignment, though, I want to focus on the visualizations.\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(plotly)\n\n\n\n\nCode\nNHLDraft<-read.csv(\"NHLDraft.csv\")\nNHLDictionary<-read_excel(\"NHLDictionary.xlsx\")\nglimpse(NHLDraft)\n\n\nRows: 105,936\nColumns: 12\n$ X           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ draftyear   <int> 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001…\n$ name        <chr> \"Drew Fata\", \"Drew Fata\", \"Drew Fata\", \"Drew Fata\", \"Drew …\n$ round       <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ overall     <int> 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86…\n$ pickinRound <int> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23…\n$ height      <int> 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73…\n$ weight      <int> 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209…\n$ position    <chr> \"Defense\", \"Defense\", \"Defense\", \"Defense\", \"Defense\", \"De…\n$ playerId    <int> 8469535, 8469535, 8469535, 8469535, 8469535, 8469535, 8469…\n$ postdraft   <int> 0, 1, 2, 4, 5, 10, 11, 12, 13, 3, 6, 7, 8, 9, 14, 15, 16, …\n$ NHLgames    <int> 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nCode\nknitr::kable(NHLDictionary)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\ndraftyear\nOrdinal\nCalendar year in which the player was drafted into the NHL.\n\n\nname\nItem\nFull name of the player.\n\n\nround\nOrdinal\nRound in which the player was drafted (1 to 7).\n\n\noverall\nOrdinal\nOverall draft position of the player (1 to 224)\n\n\npickinRound\nOrdinal\nPosition in which the player was drafted in their round (1 to 32).\n\n\nheight\nQuantitative\nPlayer height in inches.\n\n\nweight\nQuantitative\nPlayer weight in pounds.\n\n\nposition\nCategorical\nPlayer position (Forward, Defense, Goaltender)\n\n\nplayerId\nItem\nUnique ID (key) assigned to each player.\n\n\npostdraft\nOrdinal\nNumber of seasons since being drafted (0 to 20).\n\n\nNHLgames\nQuantitative\nNumber of games played in the NHL in that particular season (regular season is 82 games, playoffs are up to 28 more).\n\n\n\n\n\nIn this case, we have a dataframe with all the drafted players since 2000, their position, their draft year and position, and then rows for each season since being drafted (postdraft). The key variable here is NHLgames, which tells us how many games they played in the NHL each season since being drafted."
  },
  {
    "objectID": "posts/assignment-5/index.html#simple-scatterplot",
    "href": "posts/assignment-5/index.html#simple-scatterplot",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "SIMPLE SCATTERPLOT",
    "text": "SIMPLE SCATTERPLOT\nOne thing to realize about professional hockey is that it is pretty rare for a player to play in the NHL right after being drafted. Players get drafted when they are 18 years old, and they usually play in the juniors, minor leagues, or the NCAA for a bit to further develop. Let’s use a scatterplot to visualize this phenomenon with the most recent draft classes.\n\n\nCode\ndraft2022<-NHLDraft%>%\n  filter(draftyear==2022 & postdraft==0)\n\nggplot(draft2022, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\n\nAs you can see, the players drafted in June of 2022 haven’t played much this season. There are few things wrong with this visualization, however:\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you think of a way that adding extra channels might help?\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualization is intended to facilitate, as well as the marks, channels, and key-value pairs used.\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?\n\n\nSolution:\n\n\nCode\nggplot(draft2022, aes(x=as.factor(round), fill = factor(NHLgames))) +\n  geom_bar(position = \"stack\", stat = \"count\")+\n  geom_text(aes(label = paste0(\"n=\", after_stat(count))), stat='count', position = position_stack(vjust = 0.5)) +\n  theme_classic()+ \n  labs(title = \"Fig 1. The # of games after a player been drafted\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nI don’t know how to adjust the y-axis according to the count instead of the scale from 0 to 1.\n\nSolution: changing the position of geom_bar from fill to stack."
  },
  {
    "objectID": "posts/assignment-5/index.html#expanded-scatterplot",
    "href": "posts/assignment-5/index.html#expanded-scatterplot",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "EXPANDED SCATTERPLOT",
    "text": "EXPANDED SCATTERPLOT\nThe data from the most recent draft isn’t really helpful for our question. Let’s go back in time and use a draft year that has had some time to develop and reach their potential. How about 2018?\n\n\nCode\ndraft2018<-NHLDraft%>%\n  filter(draftyear==2018 & postdraft<6)\n\nggplot(draft2018, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\n\nHmmm… in addition to the problem of overplotting, we’ve got an additional issue here. We actually have two keys and one attribute. The attribute is NHLgames, and the keys are round and postdraft, but we are only using round.\nPostdraft indicates the number of seasons after being drafted. We have several choices here. We can make a visualization that uses both keys, or we can somehow summarize the data for one of the keys.\nFor example, let’s say we just wanted to know the TOTAL number of NHL games played since being drafted.\n\n\nCode\ndrafttot2018<- draft2018%>%\n  group_by(playerId, round, overall, position, name)%>%\n  summarise(totgames=sum(NHLgames))\n\n\n`summarise()` has grouped output by 'playerId', 'round', 'overall', 'position'.\nYou can override using the `.groups` argument.\n\n\nCode\nggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()\n\n\n\n\n\nFine, I guess, but we still have to deal with overplotting, and think about whether a scatterplot really helps us accomplish our task. For this figure do the following:\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you you think of a way that adding extra channels might help?\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used.\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?\n\n\nSolution\n\n\nCode\ndrafttot2018 <- transform(\n  drafttot2018, has_game = ifelse(totgames>0, TRUE, FALSE)\n)\nggplot(drafttot2018, aes(x=as.factor(round), fill = factor(has_game))) +\n  geom_bar(stat = \"count\",\n           #position = drafttot2018$NHLgames\n           position = \"stack\"\n           )+\n  geom_text(aes(label = paste0(factor(has_game))), stat='count', position = position_stack(vjust = 0.5)) +\n  labs(title = \"Fig 2.2 Games after a player been drafted for 6 seasons\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\nCode\nggplot(drafttot2018, aes(x=as.factor(round), fill = factor(totgames))) +\n  geom_bar(stat = \"count\",\n           #position = drafttot2018$NHLgames\n           position = \"fill\"\n           )+\n  geom_text(aes(label = paste0(totgames)), stat='count', position = position_fill(vjust = 0.5)) +\n  labs(title = \"Fig 2.1 Games after a player been drafted for 6 seasons\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2018\")"
  },
  {
    "objectID": "posts/assignment-5/index.html#scatterplot-with-overall-draft-position",
    "href": "posts/assignment-5/index.html#scatterplot-with-overall-draft-position",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "SCATTERPLOT WITH OVERALL DRAFT POSITION",
    "text": "SCATTERPLOT WITH OVERALL DRAFT POSITION\nThis approach might yield a better match with the scatterplot idiom. What if we ignore draft round, and use the player’s overall draft position instead?\n\n\nCode\nggplot(drafttot2018, aes(x=overall, y=totgames))+\n  geom_point()\n\n\n\n\n\nFor this figure, address the following:\n\nWe are trying to address the notion of trading a pick from round 1 for picks from round 2 and 3. Add visual channels to this plot that will help us make that decision.\nCreate a caption and better axis labels for this figure.\nWhat if we wanted to use more than just the 2018 draft class?\n\n\nSolution\n\n\nCode\n# library(reshape2)\n# test_df <- melt(data.frame(drafttot2018$overall, drafttot2018$totgames)) %>%\n#   mutate(val_trimmed = case_when(\n#     drafttot2018$overall > 32 * 2 ~ 32 * 2,\n#     drafttot2018$overall < 32 ~ 32,\n#     T ~ drafttot2018$overall\n#   ))\n\ncols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\nggplot(subset(drafttot2018, round <= 3), aes(x=overall, y=totgames, color = factor(round)))+\n  geom_point()+\n  scale_color_manual(values = cols) +\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.1 Total games for the players from first three round\",\n              subtitle = \"Channel: Position, Mark: Point\",\n              caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\nCode\n# options(dplyr.summarise.inform = FALSE)\n# draft_postdraft_l6<-NHLDraft%>%\n#   filter(postdraft<6)\n# \n# drafttot_postdraft_l6<- draft_postdraft_l6%>%\n#   group_by(draftyear, playerId, round, overall, position, name)%>%\n#   summarise(totgames=sum(NHLgames))\n# \n# cols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\n# ggplot(subset(drafttot_postdraft_l6, round <= 3), aes(x=overall, y=totgames, shape = factor(round), color = factor(draftyear)))+\n#   geom_point()+\n#   #scale_color_manual(values = cols) +\n#   scale_x_continuous(name =\"Position of the players\")+\n#   labs(title = \"Fig 3.2 Games for first three round players (post draft < 6)\",\n#               subtitle = \"Channel: Position, Mark: Point\",\n#               caption = \"The draft years from 2000 to 2022\")\n\n\n\n\nCode\n# https://r-graph-gallery.com/histogram_several_group.html\n# http://www.sthda.com/english/wiki/wiki.php?id_contents=7904\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nCode\n#library(forcats)\n\noptions(dplyr.summarise.inform = FALSE)\ndraft_postdraft_l6<-NHLDraft%>%\n  filter(postdraft<6)\n\ndrafttot_postdraft_l6<- draft_postdraft_l6%>%\n  group_by(draftyear, playerId, round, overall, position, name)%>%\n  summarise(totgames=sum(NHLgames))\n\nggplot(subset(drafttot_postdraft_l6, round <= 3), \n       aes(x=overall, y=totgames, color=factor(round))) + \n  geom_point() + \n  scale_fill_viridis(discrete=TRUE) +\n  scale_color_viridis(discrete=TRUE) +\n  xlab(\"\") +\n  ylab(\"totgames\") +\n  #facet_grid( ~ draftyear)\n  facet_wrap(~draftyear)+\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.2 Games for first three round players (post draft < 6)\",\n              subtitle = \"Channel: Position, Mark: Point\",\n              caption = \"The draft years from 2000 to 2022\")\n\n\n\n\n\nCode\n# p <- data %>%\n#   #mutate(text = fct_reorder(draftyear, totgames)) %>%\n#   ggplot( aes(x=overall, color=factor(draftyear), fill=factor(draftyear))) +\n#     geom_histogram(alpha=0.6, binwidth = 5) +\n#     scale_fill_viridis(discrete=TRUE) +\n#     scale_color_viridis(discrete=TRUE) +\n#     #theme_ipsum() +\n#     # theme(\n#     #   legend.position=\"none\",\n#     #   panel.spacing = unit(0.1, \"lines\"),\n#     #   strip.text.x = element_text(size = 8)\n#     # ) +\n#     xlab(\"\") +\n#     ylab(\"totgames\") +\n#     facet_wrap(~draftyear)\n# p"
  },
  {
    "objectID": "posts/assignment-5/index.html#scatterplot-summary",
    "href": "posts/assignment-5/index.html#scatterplot-summary",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "SCATTERPLOT SUMMARY",
    "text": "SCATTERPLOT SUMMARY\nWe seem to be running into an issue in terms of overplotting. Scatterplots are great, but they work best for two quantitative attributes, and we have a situation with one or two keys and one quantitative attribute. The thing is, scatterplots can be very useful when part of our workflow involves modeling the data in some way. We’ll cover this kind of thing in future assignments, but just a bit of foreshadowing here:\n\n\nCode\nggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()+\n  geom_smooth()\n\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\nAdding the smoothed line doesn’t eliminate the overplotting problem, but it does indicate that it exists. We’ll cover other potential solutions (including Cody’s violin plots!) to this issue later in the course, when we get to the notions of faceting and data reduction.\n\nSolution\n\n\nCode\ncols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\nggplot(subset(drafttot2018, round <= 3), aes(x=overall, y=totgames, color = factor(round)))+\n  geom_point()+\n  geom_smooth()+\n  scale_color_manual(values = cols) +\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.1 Total games for the players from first three round\",\n              subtitle = \"Channel: Position, Mark: Point, Line\",\n              caption = \"The draft year of 2018\")\n\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/assignment-5/index.html#simple-bar-chart",
    "href": "posts/assignment-5/index.html#simple-bar-chart",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "SIMPLE BAR CHART",
    "text": "SIMPLE BAR CHART\nOne of the best ways to deal with overplotting is to use our keys to SEPARATE and ORDER our data. Let’s do that now. I’ll stick with the summarized data for the 2018 draft year for now.\n\n\nCode\nggplot(drafttot2018, aes(x = name, y=totgames))+\n  geom_col()\n\n\n\n\n\nEpic. We now have a bar (column, really) chart with the key being player name, and the attribute being the total number of games played. We’ve SEPARATED the data using the spatial x-axis position channel, and aligned to that axis as well. But this visualization clearly sucks. You need to make it better by:\n\nAdding a visual channel indicating draft round.\nFixing the order of the x axis.\nMaking a caption and better axis labels.\nFixing the values of the x axis labels so they aren’t such a mess.\n\n\nSolution\n\n\nCode\ndrafttot2018_sorted  <- drafttot2018[order(drafttot2018$round), ]\n\ncolor_palette <- viridis(length(unique(drafttot2018_sorted$round)))\n\nplot <- plot_ly(drafttot2018_sorted, x = ~name, y = ~totgames, type = \"bar\", color = ~as.factor(round),\n                colors = color_palette)\nplot <- plot %>%\n  layout(xaxis = list(type = \"category\", automargin = TRUE),\n         margin = list(l = 100),\n         title = list(text = paste0('Fig 4.1 Total games for the players',\n                                    '<br>',\n                                    '<sup>',\n                                    'Channel: Position, Mark: Point, Line',\n                                    '</sup>')),\n         annotations = \n           list(x = 1, y = -0.1, text = \"The draft year of 2018\", \n                showarrow = F, xref='paper', yref='paper', \n                xanchor='right', yanchor='auto', xshift=0, yshift=-100,\n                font=list(size=15, color=\"black\")))%>%\n  config(scrollZoom = TRUE)%>%\n  layout(xaxis = list(categoryorder = \"array\", categoryarray = drafttot2018_sorted$name))\n\nggplotly(plot)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI tried to suppress the warning messages here by suppressWarnings() but failed."
  },
  {
    "objectID": "posts/assignment-5/index.html#stacked-bar",
    "href": "posts/assignment-5/index.html#stacked-bar",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "STACKED BAR?",
    "text": "STACKED BAR?\nStacked bar charts use two keys and one value. Can we leverage this idiom? Perhaps if we used both round and postdraft as our keys and NHLgames as our value…\nThe idea here is that we might be able to get a sense of the temporal pattern of NHL games after a player is drafted. Do first round picks join the NHL earlier? Do they stay in the NHL longer? That kind of thing.\n\n\nCode\nggplot(draft2018, aes(x = postdraft, y=NHLgames, fill=as.factor(round)))+\n  geom_col(position = \"stack\")\n\n\n\n\n\nThis seems like it has some potential, but it definitely needs some work (by you):\n\nYou know the drill by now. Caption! Labels!\nImprove the color palette.\nDo we really only want data from the 2018 draft class?\nConsider the order of rounds within the stack (glyph). Which round is most important? Change the order within the glyphs to reflect this.\n\n\nSolution\n\n\nCode\nggplot(draft2018, aes(x = as.factor(postdraft), y=NHLgames, fill=factor(round, levels = rev(unique(round)))))+\n  geom_col(position = \"stack\")+\n  scale_fill_viridis(discrete = TRUE, direction = -1)+\nlabs(title = \"Fig 5.1 NHLgames for the players according to postdraft\",\n     subtitle = \"Channel: Length, Color, Mark: Line\",\n     caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI don’t quite understand the question: > Do we really only want data from the 2018 draft class?\nDo you mean we should plot other stacked charts with different x-axis?\n\n\n\n\nCode\nggplot(draft2018, aes(x = as.factor(pickinRound), y=NHLgames, fill=factor(round, levels = rev(unique(round)))))+\n  geom_col(position = \"stack\")+\n  scale_fill_viridis(discrete = TRUE, direction = -1)+\nlabs(title = \"Fig 5.2 NHLgames for the players according to pickinRound\",\n     subtitle = \"Channel: Length, Color, Mark: Line\",\n     caption = \"The draft year of 2018\")"
  },
  {
    "objectID": "posts/assignment-5/index.html#pie-charts-normalized-bar-charts",
    "href": "posts/assignment-5/index.html#pie-charts-normalized-bar-charts",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "PIE CHARTS / NORMALIZED BAR CHARTS",
    "text": "PIE CHARTS / NORMALIZED BAR CHARTS\nWe all know that Pie Charts are rarely a good choice, but let’s look at how to make one here. I’ll eliminate all the players drafted in 2018 who never played an NHL game, leaving us 80 players drafted in that year who made “THE SHOW”. Let’s look at how those 80 players were drafted:\n\n\nCode\nplayedNHL2018 <- drafttot2018%>%\n  filter(totgames>0)\n\nggplot(playedNHL2018, aes(x = \"\", fill = factor(round))) +\n  geom_bar(width = 1) +\n  coord_polar(theta = \"y\")\n\n\n\n\n\nObviously this isn’t great, but can you state why? Write a little critique of this visualizaiton that:\n\nConsiders a player who played hundreds of games over their first five years vs a player who played one game in five years.\nEvaluates the relative value of a second round pick and a third round pick.\n\n\nMy critique\n\nThis pie chart presented all the players with positive values in 2018 NHL games, but neglected the number of the games, which weaken the values of frequent game players within each round.\nThe pie chart without a proper legend will result in a difficulty to reader to quickly recognize the difference between similar valued pies.\n\nNow let’s change this to account for the various years post draft:\n\n\nCode\nseasonplayedNHL2018 <- draft2018%>%\n  filter(NHLgames>0)\n\n\nggplot(seasonplayedNHL2018, aes(x = \"\", fill = factor(round))) +\n  geom_bar(width = 1) +\n  coord_polar(theta = \"y\")+\n  facet_wrap(~postdraft)\n\n\n\n\n\nSeems like there is something to work with here, but let’s compare this to a normalized bar chart:\n\n\nCode\nggplot(draft2018, aes(x = postdraft, y=NHLgames, fill=as.factor(round)))+\n  geom_col(position = \"fill\")\n\n\nWarning: Removed 218 rows containing missing values (geom_col).\n\n\n\n\n\nCan you work with this to make it a useful visualization for your friend, Cassandra Canuck?\n\n\nSolution\n\n\nCode\nggplot(draft2018, aes(x = as.factor(postdraft), y = NHLgames, fill = as.factor(round))) +\n  geom_bar(stat = \"identity\", position = \"stack\")+\nlabs(title = \"Fig 6.1 NHLgames for postdraft\",\n     subtitle = \"Channel: Length, Color; Mark: Line\",\n     caption = \"The draft year of 2018\")"
  },
  {
    "objectID": "posts/assignment-5/index.html#heatmap",
    "href": "posts/assignment-5/index.html#heatmap",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "HEATMAP?",
    "text": "HEATMAP?\nCould this be useful?\n\n\nCode\nround1<-NHLDraft%>%\n  filter(round==1)\n\nggplot(round1, aes(y = reorder(name, overall), x = postdraft, fill = NHLgames)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"blue\", high = \"red\")\n\n\n\n\n\n\nSolution\n\n\nCode\nNHLDraft_summary <- NHLDraft%>%\n  filter(round<4)%>%\n  group_by(round, postdraft) %>%\n  summarise(total_NHLgames = sum(NHLgames))\n\n\nheatmap <- ggplot(NHLDraft_summary, aes(y = round, x = postdraft, fill = total_NHLgames)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"blue\", high = \"red\")+\nlabs(title = \"Fig 7.1 NHLgames heat map for postdraft\",\n     subtitle = \"Channel: Position; Mark: Color\",\n     caption = \"The draft year of 2000-2022\")\n\nheatmap"
  },
  {
    "objectID": "posts/assignment-5/index.html#other-stuff-to-consider",
    "href": "posts/assignment-5/index.html#other-stuff-to-consider",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "OTHER STUFF TO CONSIDER",
    "text": "OTHER STUFF TO CONSIDER\n\nDo these visualizations change as a function of player position?\nIs the number of NHL games played really the best metric to use?\n\n\nSolution\n\nSome visualizations considered the position of the players, e.g. Fig 3.1, 3.2. Therefore the scatters will change subject to the change in position data. But some other visualization grouped the position values in a round, therefore the change won’t reflected in the results of visualization.\nThe NHL games and totgames share the same tendency that the players with prior round tend to have more games. NHL games as a more competitive game can stand for a better performance of a player, but this value can be very limited in the early years for a young play. In that situation, the totgames would be a better choice to delineate the value of early-career players."
  },
  {
    "objectID": "posts/assignment-5/index.html#conclusion",
    "href": "posts/assignment-5/index.html#conclusion",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nBased on your visualizations, what would you advise regarding this trade proposal? Why?\n\nSolution\nTrading one first-round player to two second-round players plus one third-round player seems plausible.\nThe first-round players have the dominant number of games and NHL games in history. The second-round players cannot achieve half the number of games compared to the first. Nor to mention the further rounds. But the total number of games of 2 second-round players plus a third-round player seems plausible compared with one first-round player.\nI wonder what factors determine the profit of hockey games. Concerning whether the cost of training one good player is economical compared with three other players."
  },
  {
    "objectID": "posts/assignment-5/index.html#solution",
    "href": "posts/assignment-5/index.html#solution",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution:",
    "text": "Solution:\n\n\nCode\nggplot(draft2022, aes(x=as.factor(round), fill = factor(NHLgames))) +\n  geom_bar(position = \"stack\", stat = \"count\")+\n  geom_text(aes(label = paste0(\"n=\", after_stat(count))), stat='count', position = position_stack(vjust = 0.5)) +\n  theme_classic()+ \n  labs(title = \"Fig 1. The # of games after a player been drafted\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2022\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nI don’t know how to adjust the y-axis according to the count instead of the scale from 0 to 1.\n\nSolution: changing the position of geom_bar from fill to stack."
  },
  {
    "objectID": "posts/assignment-5/index.html#solution-1",
    "href": "posts/assignment-5/index.html#solution-1",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution",
    "text": "Solution\n\n\nCode\ndrafttot2018 <- transform(\n  drafttot2018, has_game = ifelse(totgames>0, TRUE, FALSE)\n)\nggplot(drafttot2018, aes(x=as.factor(round), fill = factor(has_game))) +\n  geom_bar(stat = \"count\",\n           #position = drafttot2018$NHLgames\n           position = \"stack\"\n           )+\n  geom_text(aes(label = paste0(factor(has_game))), stat='count', position = position_stack(vjust = 0.5)) +\n  labs(title = \"Fig 2.2 Games after a player been drafted for 6 seasons\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\nCode\nggplot(drafttot2018, aes(x=as.factor(round), fill = factor(totgames))) +\n  geom_bar(stat = \"count\",\n           #position = drafttot2018$NHLgames\n           position = \"fill\"\n           )+\n  geom_text(aes(label = paste0(totgames)), stat='count', position = position_fill(vjust = 0.5)) +\n  labs(title = \"Fig 2.1 Games after a player been drafted for 6 seasons\",\n              subtitle = \"Channel: Length, Mark: Bars\",\n              caption = \"The draft year of 2018\")"
  },
  {
    "objectID": "posts/assignment-5/index.html#solution-2",
    "href": "posts/assignment-5/index.html#solution-2",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution",
    "text": "Solution\n\n\nCode\n# library(reshape2)\n# test_df <- melt(data.frame(drafttot2018$overall, drafttot2018$totgames)) %>%\n#   mutate(val_trimmed = case_when(\n#     drafttot2018$overall > 32 * 2 ~ 32 * 2,\n#     drafttot2018$overall < 32 ~ 32,\n#     T ~ drafttot2018$overall\n#   ))\n\ncols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\nggplot(subset(drafttot2018, round <= 3), aes(x=overall, y=totgames, color = factor(round)))+\n  geom_point()+\n  scale_color_manual(values = cols) +\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.1 Total games for the players from first three round\",\n              subtitle = \"Channel: Position, Mark: Point\",\n              caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\nCode\n# options(dplyr.summarise.inform = FALSE)\n# draft_postdraft_l6<-NHLDraft%>%\n#   filter(postdraft<6)\n# \n# drafttot_postdraft_l6<- draft_postdraft_l6%>%\n#   group_by(draftyear, playerId, round, overall, position, name)%>%\n#   summarise(totgames=sum(NHLgames))\n# \n# cols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\n# ggplot(subset(drafttot_postdraft_l6, round <= 3), aes(x=overall, y=totgames, shape = factor(round), color = factor(draftyear)))+\n#   geom_point()+\n#   #scale_color_manual(values = cols) +\n#   scale_x_continuous(name =\"Position of the players\")+\n#   labs(title = \"Fig 3.2 Games for first three round players (post draft < 6)\",\n#               subtitle = \"Channel: Position, Mark: Point\",\n#               caption = \"The draft years from 2000 to 2022\")\n\n\n\n\nCode\n# https://r-graph-gallery.com/histogram_several_group.html\n# http://www.sthda.com/english/wiki/wiki.php?id_contents=7904\nlibrary(viridis)\n\n\nLoading required package: viridisLite\n\n\nCode\n#library(forcats)\n\noptions(dplyr.summarise.inform = FALSE)\ndraft_postdraft_l6<-NHLDraft%>%\n  filter(postdraft<6)\n\ndrafttot_postdraft_l6<- draft_postdraft_l6%>%\n  group_by(draftyear, playerId, round, overall, position, name)%>%\n  summarise(totgames=sum(NHLgames))\n\nggplot(subset(drafttot_postdraft_l6, round <= 3), \n       aes(x=overall, y=totgames, color=factor(round))) + \n  geom_point() + \n  scale_fill_viridis(discrete=TRUE) +\n  scale_color_viridis(discrete=TRUE) +\n  xlab(\"\") +\n  ylab(\"totgames\") +\n  #facet_grid( ~ draftyear)\n  facet_wrap(~draftyear)+\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.2 Games for first three round players (post draft < 6)\",\n              subtitle = \"Channel: Position, Mark: Point\",\n              caption = \"The draft years from 2000 to 2022\")\n\n\n\n\n\nCode\n# p <- data %>%\n#   #mutate(text = fct_reorder(draftyear, totgames)) %>%\n#   ggplot( aes(x=overall, color=factor(draftyear), fill=factor(draftyear))) +\n#     geom_histogram(alpha=0.6, binwidth = 5) +\n#     scale_fill_viridis(discrete=TRUE) +\n#     scale_color_viridis(discrete=TRUE) +\n#     #theme_ipsum() +\n#     # theme(\n#     #   legend.position=\"none\",\n#     #   panel.spacing = unit(0.1, \"lines\"),\n#     #   strip.text.x = element_text(size = 8)\n#     # ) +\n#     xlab(\"\") +\n#     ylab(\"totgames\") +\n#     facet_wrap(~draftyear)\n# p"
  },
  {
    "objectID": "posts/assignment-5/index.html#solution-3",
    "href": "posts/assignment-5/index.html#solution-3",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution",
    "text": "Solution\n\n\nCode\ncols <- c(\"#1170AA\", \"#55AD89\", \"#EF6F6A\")\nggplot(subset(drafttot2018, round <= 3), aes(x=overall, y=totgames, color = factor(round)))+\n  geom_point()+\n  geom_smooth()+\n  scale_color_manual(values = cols) +\n  scale_x_continuous(name =\"Position of the players\")+\n  labs(title = \"Fig 3.1 Total games for the players from first three round\",\n              subtitle = \"Channel: Position, Mark: Point, Line\",\n              caption = \"The draft year of 2018\")\n\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/assignment-5/index.html#solution-4",
    "href": "posts/assignment-5/index.html#solution-4",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution",
    "text": "Solution\n\n\nCode\ndrafttot2018_sorted  <- drafttot2018[order(drafttot2018$round), ]\n\ncolor_palette <- viridis(length(unique(drafttot2018_sorted$round)))\n\nplot <- plot_ly(drafttot2018_sorted, x = ~name, y = ~totgames, type = \"bar\", color = ~as.factor(round),\n                colors = color_palette)\nplot <- plot %>%\n  layout(xaxis = list(type = \"category\", automargin = TRUE),\n         margin = list(l = 100),\n         title = list(text = paste0('Fig 4.1 Total games for the players',\n                                    '<br>',\n                                    '<sup>',\n                                    'Channel: Position, Mark: Point, Line',\n                                    '</sup>')),\n         annotations = \n           list(x = 1, y = -0.1, text = \"The draft year of 2018\", \n                showarrow = F, xref='paper', yref='paper', \n                xanchor='right', yanchor='auto', xshift=0, yshift=-100,\n                font=list(size=15, color=\"black\")))%>%\n  config(scrollZoom = TRUE)%>%\n  layout(xaxis = list(categoryorder = \"array\", categoryarray = drafttot2018_sorted$name))\n\nggplotly(plot)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI tried to suppress the warning messages here by suppressWarnings() but failed."
  },
  {
    "objectID": "posts/assignment-5/index.html#solution-5",
    "href": "posts/assignment-5/index.html#solution-5",
    "title": "ASSIGNMENT 5: Happy Hockey",
    "section": "Solution",
    "text": "Solution\n\n\nCode\nggplot(draft2018, aes(x = as.factor(postdraft), y=NHLgames, fill=factor(round, levels = rev(unique(round)))))+\n  geom_col(position = \"stack\")+\n  scale_fill_viridis(discrete = TRUE, direction = -1)+\nlabs(title = \"Fig 5.1 NHLgames for the players according to postdraft\",\n     subtitle = \"Channel: Length, Color, Mark: Line\",\n     caption = \"The draft year of 2018\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nI don’t quite understand the question: > Do we really only want data from the 2018 draft class?\nDo you mean we should plot other stacked charts with different x-axis?\n\n\n\n\nCode\nggplot(draft2018, aes(x = as.factor(pickinRound), y=NHLgames, fill=factor(round, levels = rev(unique(round)))))+\n  geom_col(position = \"stack\")+\n  scale_fill_viridis(discrete = TRUE, direction = -1)+\nlabs(title = \"Fig 5.2 NHLgames for the players according to pickinRound\",\n     subtitle = \"Channel: Length, Color, Mark: Line\",\n     caption = \"The draft year of 2018\")"
  },
  {
    "objectID": "posts/midterm-post/index.html",
    "href": "posts/midterm-post/index.html",
    "title": "From Midterms to Championships: Hopw to Build Winning Pokémon Teams",
    "section": "",
    "text": "PREAMBLE\n\n\nCode\nlibrary(igraph)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\nlibrary(jsonlite)\n\n\n\nPOKEMONS.\n\nSmogon is a popular online community of competitive Pokémon players that was founded in 2004. The community focuses on the competitive side of Pokémon battling, providing resources such as guides, forums, and a tier system that classifies Pokémon based on their power level. Smogon’s tier system is used by many competitive players to build their teams and strategies. The community also hosts tournaments and events for players to compete in.\nPokemon Showdown is an online battle simulator created by Smogon that allows players to build and battle with Pokémon teams in a virtual environment. It is widely used by the competitive Pokémon community and is an important tool for testing and refining strategies. Players can customize their teams with specific moves, items, and abilities, and then battle against other players in real-time.\nThe objective of this study is to develop effective visualizations for the comprehensive datasets available in the Smogon databases. The aim is to present the Pokemon battle data in a clear and intuitive manner using visual plots. Through the use of such visualizations, I aim to provide valuable insights and suggestions to users on how to build a successful Pokemon battle team. Our approach seeks to enhance the user’s understanding of the data by presenting it in a visually engaging format, thereby enabling them to make informed decisions when building their team. The ultimate goal is to offer an optimized user experience that facilitates an improved decision-making process and increases the success rate of the user’s Pokemon battle team.\n\n\nData Preparation\n\n\nCode\nimport os\nimport requests\nfrom lxml import html\nfrom pathlib import Path\nimport sys\n\nurl = \"https://www.smogon.com/stats/\"\ndata_dir = os.path.join(os.getcwd(), \"data\")\n\ndef download_files(url, dir_path=data_dir):\n    # use pathlib to create the directory whether the parent directory exists or not\n    Path(dir_path).mkdir(parents=True, exist_ok=True)\n\n    response = requests.get(url)\n    parsed_body = html.fromstring(response.content)\n\n    for index in range(1, 65535):\n        try:\n            link = parsed_body.xpath(\"/html/body/pre/a[{index}]\".format(index=index))[0]\n        except IndexError:\n            break\n        text = link.text\n        if \"..\" in text:\n            continue\n        if \".\" in text:\n            file_url = url + text\n            file_path = os.path.join(dir_path, file_url.split(\"/\")[-1])\n            print(\"Downloading\", file_url)\n            r = requests.get(file_url)\n            with open(file_path, \"wb\") as f:\n                f.write(r.content)\n            print(\"Downloaded\", file_url)\n            #sys.exit()\n        else:\n            new_url = url + text\n            new_dir = os.path.join(dir_path, text)\n            download_files(new_url, new_dir)\n\n\ndef batch_download_by_year(YEAR):\n    response = requests.get(url)\n    parsed_body = html.fromstring(response.content)\n    for index in range(1, 65535):\n        try:\n            link = parsed_body.xpath(\"/html/body/pre/a[{index}]\".format(index=index))[0]\n        except IndexError:\n            break\n        text = link.text\n        if str(YEAR) in text:\n            print(\"Downloading\", YEAR)\n            new_url = url + text\n            new_dir = os.path.join(data_dir, str(YEAR), text)\n            download_files(new_url, new_dir)\n\n    year_url = url + str(YEAR) + \"/\"\n    year_dir = os.path.join(data_dir, str(YEAR))\n    download_files(year_url, year_dir)\n\n\ndef _test_parse():\n    response = requests.get(url)\n    parsed_body = html.fromstring(response.content)\n    link = parsed_body.xpath(\"/html/body/pre/a[999]\")[0]\n    #text = link.text\n    #print(text)\n\nif __name__ == \"__main__\":\n    batch_download_by_year(2023)\n\n\n\nI managed to grab a huge bunch of data from the Smogon forum since it is hard to collect similar Pokemon battle data from official websites, except for some crazy poke fans who can manually recognize and record the Pokemon ranking information and player teams from the official competition videos. The collected data can be accessed from this source. My local data collection is managed accordingly to the file hierarchy of this straightforward website. My current work focuses on the data recorded in 2023. The Pokemon battle data are stored in .txt and .json formats. I am working on reading some forum threads about the data discussion and explanations. The next plan is to convert the interesting part of the data into an R data frame and end up with visualizations.\n\n\nI applied the dataset called gen9vgc2023series2-1630 for this pokemon battle research.\ngen9 stands for the 9th generation of pokemon of Scarlet & Violet. The games will feature a brand new open-world region, three original starters, and new Legendaries for players to discover.\nvgc2023 stands for the Pokemon VGC (Video Game Championships) rules in 2023. The rules can vary slightly from year to year, but generally, the VGC format is a double battle format where each player brings a team of six Pokemon and chooses four of them to use in each battle. Players can only use Pokemon from the current generation of games, and there are restrictions on which Pokemon are allowed based on their species, level, and items.\nseries2 refers to detailed battle rules. This series allows trainers to use a team of 3-6 Pokémon (for Singles) or 4-6 Pokémon (for Doubles) from Level 1 to Level 100, with all Pokémon then set to Level 50. There are more details omitted here.\n1630 stands for a specific battle tiers for a fan-made rules.\n\n\nCode\n# Read the CSV files\npokemon_data <- read_csv(\"gen9vgc2023series2-1630.csv\")\npokemon_data$`Usage%` <- as.numeric(gsub(\"%\", \"\", pokemon_data$`Usage%`))\nedge_data <- read_csv(\"teammates.csv\")\n\n# Filter the top 50 Pokemon\ntop_20_pokemon <- head(pokemon_data, 20)\n\n\n\n\n\nFlutter Mane\n\n\n\nThe most popular pokemon till Feb, 2023: Flutter Mane.\n\n\n\nCode\ntop_20_pokemon\n\n\n# A tibble: 20 × 7\n    Rank Pokemon      `Usage%`     Raw `Raw%`    Real `Real%`\n   <dbl> <chr>           <dbl>   <dbl> <chr>    <dbl> <chr>  \n 1     1 Flutter Mane     54.6 1454951 38.720% 729736 42.412%\n 2     2 Iron Bundle      40.8 1165153 31.007% 561782 32.651%\n 3     3 Iron Hands       32.4 1145260 30.478% 617069 35.864%\n 4     4 Great Tusk       27.8  673071 17.912% 364773 21.201%\n 5     5 Amoonguss        26.3  983437 26.172% 371485 21.591%\n 6     6 Arcanine         24.3  930540 24.764% 433178 25.176%\n 7     7 Gholdengo        22.0  663711 17.663% 299077 17.382%\n 8     8 Roaring Moon     18.5  642275 17.092% 268052 15.579%\n 9     9 Kingambit        17.4  556369 14.806% 238494 13.861%\n10    10 Dragonite        17.0  396729 10.558% 160427 9.324% \n11    11 Dondozo          16.2  315148 8.387%  166119 9.655% \n12    12 Armarouge        15.9  524411 13.956% 262358 15.248%\n13    13 Indeedee-F       15.8  532736 14.177% 235561 13.691%\n14    14 Tatsugiri        15.8  313274 8.337%  176483 10.257%\n15    15 Maushold         15.8  452690 12.047% 186586 10.844%\n16    16 Talonflame       15.6  476666 12.685% 138081 8.025% \n17    17 Brute Bonnet     14.0  374798 9.974%  156833 9.115% \n18    18 Tyranitar        12.3  314751 8.376%  149872 8.711% \n19    19 Annihilape       12.2  514816 13.700% 252072 14.650%\n20    20 Palafin          11.9  416057 11.072% 235410 13.682%\n\n\n\n\n\nThe given data frame provides information on the top used Pokemon in the Smogon database, along with their usage percentages, weighted and unweighted raw counts, and “real” counts. The “real” count refers only to the Pokemon that actually appear in battle, as opposed to counting all six Pokemon in a team. The data frame provides valuable insights into the popularity of different Pokemon in the Smogon community and can be used to inform strategic decisions regarding team building and battling.\n\n\nVisualizations\n\n\nCode\ntop20_pokemon_list <- pokemon_data$Pokemon[1:20]\nedge_data <- subset(edge_data, from %in% top20_pokemon_list & to %in% top20_pokemon_list)\n# Create a graph from the edge data\ng <- graph_from_data_frame(edge_data, directed = FALSE)\n\n# Set vertex attributes: size and labels\nV(g)$size <- top_20_pokemon$`Usage%`\nV(g)$label <- top_20_pokemon$Pokemon\n\n# Set edge attributes: width\nE(g)$width <- as.numeric(substr(edge_data$weight, 1, nchar(edge_data$weight) - 1)) / 100\n\n\n\n\nCode\n# Plot the graph\nlayout <- layout_nicely(g)\n\n\nWarning in (function (graph, coords = NULL, dim = 2, niter = 500, start.temp =\nsqrt(vcount(graph)), : NAs introduced by coercion\n\n\nCode\nsuppressWarnings({\nplot(g,\n     vertex.label.cex = 0.8, # Adjust the font size of vertex labels\n     vertex.label.family = \"sans\",\n     vertex.label.color = \"black\",\n     vertex.frame.color = \"black\",\n     vertex.color = \"lightblue\",\n     edge.arrow.size = 0,\n     edge.color = \"gray\",\n     #layout = layout_with_fr(g, niter = 2000) # Set the layout algorithm\n     layout = layout,\n     #vertex.label.dist = 5, # Increase the distance of the label from the vertex\n     #vertex.label.degree = 45 \n     )\ntitle(main = \"The top 20 Pokemon and their teammates\")\n})\n\n\n\n\n\nThese codes aim to create a network visualization of the top 20 Pokemon and their teammates in the gen9 VGC 2023 series 2 using the R package igraph. The code reads in two CSV files, “gen9vgc2023series2-1630.csv” and “teammates.csv”, which contain the data on the Pokemon and their teammates.\nThe graph is plotted with various visualization settings, such as adjusting the font size of vertex labels, setting the layout algorithm to layout_nicely(), and suppressing any warning messages that may arise during the plotting process. The resulting graph represents the top 20 Pokemon and their teammates as nodes and edges, respectively, with the size of each node representing its usage percentage.\nThe layout_nicely() isn’t a satisfying solution to such not even complex network. The static network appeared to be insufficient when the number of nodes and links increase.\n\n\n\n\n\n\nNote\n\n\n\nIt occurred to me that it is hard to increase the node distances. I have tried to apply the les miserable interactive network, but the code to the right side of d3= seems extremely long and very inconvenient to copy from the website. I would like to know that if I am getting anything wrong.\n\n\n\n\nCode\ngraph1 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: []\n})\n\n\ngraph2 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"},\n    {id: \"c\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"},\n    {source: \"b\", target: \"c\"},\n    {source: \"c\", target: \"a\"}\n  ]\n})\n\n\ngraph3 = ({\n  nodes: [\n    {id: \"a\"},\n    {id: \"b\"}\n  ],\n  links: [\n    {source: \"a\", target: \"b\"}\n  ]\n})\n\n\ncolor = d3.scaleOrdinal(d3.schemeTableau10)\n\nheight = 400\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nchart = ForceGraph(miserables, {\n  nodeId: d => d.id,\n  nodeGroup: d => d.group,\n  nodeTitle: d => `${d.id}\\n${d.group}`,\n  linkStrokeWidth: l => Math.sqrt(l.value),\n  width,\n  height: 600,\n  invalidation // a promise to stop the simulation when the cell is re-run\n})\n\n\n\n\n\n\n\n\n\nCode\nmiserables = FileAttachment(\"output.json\").json()\n\n\n// Copyright 2021 Observable, Inc.\n// Released under the ISC license.\n// https://observablehq.com/@d3/force-directed-graph\nfunction ForceGraph({\n  nodes, // an iterable of node objects (typically [{id}, …])\n  links // an iterable of link objects (typically [{source, target}, …])\n}, {\n  nodeId = d => d.id, // given d in nodes, returns a unique identifier (string)\n  nodeGroup, // given d in nodes, returns an (ordinal) value for color\n  nodeGroups, // an array of ordinal values representing the node groups\n  nodeTitle, // given d in nodes, a title string\n  nodeFill = \"currentColor\", // node stroke fill (if not using a group color encoding)\n  nodeStroke = \"#fff\", // node stroke color\n  nodeStrokeWidth = 1.5, // node stroke width, in pixels\n  nodeStrokeOpacity = 1, // node stroke opacity\n  nodeRadius = 5, // node radius, in pixels\n  nodeStrength,\n  linkSource = ({source}) => source, // given d in links, returns a node identifier string\n  linkTarget = ({target}) => target, // given d in links, returns a node identifier string\n  linkStroke = \"#999\", // link stroke color\n  linkStrokeOpacity = 0.6, // link stroke opacity\n  linkStrokeWidth = 1.5, // given d in links, returns a stroke width in pixels\n  linkStrokeLinecap = \"round\", // link stroke linecap\n  linkStrength,\n  colors = d3.schemeTableau10, // an array of color strings, for the node groups\n  width = 640, // outer width, in pixels\n  height = 400, // outer height, in pixels\n  invalidation // when this promise resolves, stop the simulation\n} = {}) {\n  // Compute values.\n  const N = d3.map(nodes, nodeId).map(intern);\n  const LS = d3.map(links, linkSource).map(intern);\n  const LT = d3.map(links, linkTarget).map(intern);\n  if (nodeTitle === undefined) nodeTitle = (_, i) => N[i];\n  const T = nodeTitle == null ? null : d3.map(nodes, nodeTitle);\n  const G = nodeGroup == null ? null : d3.map(nodes, nodeGroup).map(intern);\n  const W = typeof linkStrokeWidth !== \"function\" ? null : d3.map(links, linkStrokeWidth);\n  const L = typeof linkStroke !== \"function\" ? null : d3.map(links, linkStroke);\n\n  // Replace the input nodes and links with mutable objects for the simulation.\n  nodes = d3.map(nodes, (_, i) => ({id: N[i]}));\n  links = d3.map(links, (_, i) => ({source: LS[i], target: LT[i]}));\n\n  // Compute default domains.\n  if (G && nodeGroups === undefined) nodeGroups = d3.sort(G);\n\n  // Construct the scales.\n  const color = nodeGroup == null ? null : d3.scaleOrdinal(nodeGroups, colors);\n\n  // Construct the forces.\n  const forceNode = d3.forceManyBody();\n  const forceLink = d3.forceLink(links).id(({index: i}) => N[i]);\n  if (nodeStrength !== undefined) forceNode.strength(nodeStrength);\n  if (linkStrength !== undefined) forceLink.strength(linkStrength);\n\n  const simulation = d3.forceSimulation(nodes)\n      .force(\"link\", forceLink)\n      .force(\"charge\", forceNode)\n      .force(\"center\",  d3.forceCenter())\n      .on(\"tick\", ticked);\n\n  const svg = d3.create(\"svg\")\n      .attr(\"width\", width)\n      .attr(\"height\", height)\n      .attr(\"viewBox\", [-width / 2, -height / 2, width, height])\n      .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  const link = svg.append(\"g\")\n      .attr(\"stroke\", typeof linkStroke !== \"function\" ? linkStroke : null)\n      .attr(\"stroke-opacity\", linkStrokeOpacity)\n      .attr(\"stroke-width\", typeof linkStrokeWidth !== \"function\" ? linkStrokeWidth : null)\n      .attr(\"stroke-linecap\", linkStrokeLinecap)\n    .selectAll(\"line\")\n    .data(links)\n    .join(\"line\");\n\n  const node = svg.append(\"g\")\n      .attr(\"fill\", nodeFill)\n      .attr(\"stroke\", nodeStroke)\n      .attr(\"stroke-opacity\", nodeStrokeOpacity)\n      .attr(\"stroke-width\", nodeStrokeWidth)\n    .selectAll(\"circle\")\n    .data(nodes)\n    .join(\"circle\")\n      .attr(\"r\", nodeRadius)\n      .call(drag(simulation));\n\n  if (W) link.attr(\"stroke-width\", ({index: i}) => W[i]);\n  if (L) link.attr(\"stroke\", ({index: i}) => L[i]);\n  if (G) node.attr(\"fill\", ({index: i}) => color(G[i]));\n  if (T) node.append(\"title\").text(({index: i}) => T[i]);\n  if (invalidation != null) invalidation.then(() => simulation.stop());\n\n  function intern(value) {\n    return value !== null && typeof value === \"object\" ? value.valueOf() : value;\n  }\n\n  function ticked() {\n    link\n      .attr(\"x1\", d => d.source.x)\n      .attr(\"y1\", d => d.source.y)\n      .attr(\"x2\", d => d.target.x)\n      .attr(\"y2\", d => d.target.y);\n\n    node\n      .attr(\"cx\", d => d.x)\n      .attr(\"cy\", d => d.y);\n  }\n\n  function drag(simulation) {    \n    function dragstarted(event) {\n      if (!event.active) simulation.alphaTarget(0.3).restart();\n      event.subject.fx = event.subject.x;\n      event.subject.fy = event.subject.y;\n    }\n    \n    function dragged(event) {\n      event.subject.fx = event.x;\n      event.subject.fy = event.y;\n    }\n    \n    function dragended(event) {\n      if (!event.active) simulation.alphaTarget(0);\n      event.subject.fx = null;\n      event.subject.fy = null;\n    }\n    \n    return d3.drag()\n      .on(\"start\", dragstarted)\n      .on(\"drag\", dragged)\n      .on(\"end\", dragended);\n  }\n\n  return Object.assign(svg.node(), {scales: {color}});\n}\n\n\nimport {howto} from \"@d3/example-components\"\n\nimport {Swatches} from \"@d3/color-legend\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create a data frame with the usage percentages for each teammate\nteammates <- data.frame(\n  Name = c(\"Iron Bundle\", \"Great Tusk\", \"Iron Hands\", \"Arcanine\", \"Amoonguss\", \"Kingambit\", \"Dondozo\", \"Dragonite\", \"Talonflame\", \"Tatsugiri\", \"Roaring Moon\"),\n  Usage = c(37.840, 29.509, 27.440, 23.847, 23.497, 19.474, 17.338, 17.326, 16.669, 16.646, 14.669)\n)\n\n# Reorder the factor levels of the Name variable based on the Usage variable\nteammates$Name <- factor(teammates$Name, levels = teammates$Name[order(desc(teammates$Usage))])\n\n# Create a bar plot\nggplot(data = teammates, aes(x = Name, y = Usage)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Teammate Name\") +\n  ylab(\"Usage Percentage\") +\n  ggtitle(\"Usage Percentages of Teammates for Flutter Mane\")\n\n\n\n\n\nUsage Percentages of Teammates for Flutter Mane, ordered by the usage percentages.\n\n\nCode\n# Create a data frame with the names and weights of the teammates\nteammates <- data.frame(\n  from = rep(\"Flutter Mane\", times = 11),\n  to = c(\"Iron Bundle\", \"Great Tusk\", \"Iron Hands\", \"Arcanine\", \"Amoonguss\", \"Kingambit\", \"Dondozo\", \"Dragonite\", \"Talonflame\", \"Tatsugiri\", \"Roaring Moon\"),\n  weight = c(37.840, 29.509, 27.440, 23.847, 23.497, 19.474, 17.338, 17.326, 16.669, 16.646, 14.669)\n)\n\n# Create a graph object\ng <- graph_from_data_frame(teammates, directed = TRUE)\n\n# Set the vertex attributes\nV(g)$label <- V(g)$name\nV(g)$size <- 20\n\n# Set the edge attributes\nE(g)$width <- 1/100 * E(g)$weight\n\n# set size of nodes based on Usage% from top_20_pokemon\nsize <- top_20_pokemon$`Usage%`/1000\n\n# color nodes based on Usage%\ncols <- colorRampPalette(c(\"blue\", \"red\"))(length(size))\ncols <- cols[rank(rank(size))]\n\n# # Add the size legend\n# legend(\"bottomright\", \n#        legend = c(\"Usage%\"),\n#        cex = 0.8,\n#        pt.cex = 2,\n#        pt.bg = \"white\",\n#        pch = 21,\n#        pt.col = \"black\",\n#        bty = \"n\",\n#        title = \"Node Size\")\n# \n# # Add the color legend\n# legend(\"bottomleft\", \n#        legend = c(\"Low Usage\", \"High Usage\"),\n#        fill = colorRampPalette(c(\"blue\", \"red\"))(10),\n#        bty = \"n\",\n#        title = \"Node Color\")\n\n\n# Plot the graph with captions and legends\nplot(g, vertex.label.color = \"black\", vertex.color = cols, edge.color = \"gray\",\n     main = \"Pokemon Teammates Network for Flutter Mane\",\n     sub = \"Channel: Length, Marks: Lines\",\n     # vertex.size.legend = list(title = \"Usage%\", labels = c(\"Low\", \"High\")),\n     # vertex.color.legend = list(title = \"Usage%\", at = seq(0, 1, length.out = length(cols)), labels = NULL),\n     # edge.width.legend = list(title = \"Weight\", at = seq(0, 1, length.out = 5), labels = NULL)\n     )\n\n\n\n\n\nThis code creates a network visualization of the top 20 ranked Pokémon and their teammates for the Pokémon named “Flutter Mane”. The visualization shows the connections between the Pokémon and their teammates. Center node represents a Pokémon and others are teammates, and the size of the node is proportional to the Usage% of that Pokémon in battles. The color of the node represents the Usage% of the Pokémon, with blue representing low usage and red representing high usage.\nThis visualization is useful for understanding the relationships between the top-ranked Pokémon and their teammates, and can provide insights for building a strong Pokémon battle team. It can also help identify patterns in the data that may be difficult to see in a table or spreadsheet format.\n\n\nCode\n# load the necessary libraries\n\n\n# create a sample data frame of items and their frequencies\nitems <- data.frame(\n  Item = c(\"Focus Sash\", \"Choice Specs\", \"Life Orb\", \"Booster Energy\", \"Other\"),\n  Freq = c(32.151, 26.383, 24.673, 13.824, 2.969)\n)\n\n# # create a bar chart of the item frequencies\n# bar_chart <- ggplot(items, aes(x = Item, y = Freq, fill = Item)) +\n#   geom_bar(stat = \"identity\") +\n#   ggtitle(\"Item Frequencies\") +\n#   xlab(\"Item\") +\n#   ylab(\"Frequency (%)\") +\n#   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n# \n# # create a sorted bar chart of the item frequencies\n# sorted_bar_chart <- items %>%\n#   arrange(desc(Freq)) %>%\n#   ggplot(aes(x = Item, y = Freq, fill = Item)) +\n#   geom_bar(stat = \"identity\") +\n#   ggtitle(\"Item Frequencies (sorted)\") +\n#   xlab(\"Item\") +\n#   ylab(\"Frequency (%)\") +\n#   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n# create a stacked bar chart of the item frequencies by category\ncategories <- c(rep(\"Common\", 3), rep(\"Uncommon\", 1), \"Rare\")\nitem_categories <- data.frame(Item = items$Item, Category = categories, Freq = items$Freq)\nstacked_bar_chart <- ggplot(item_categories, aes(x = Category, y = Freq, fill = Item)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Item Frequencies by for Flutter Mane\") +\n  xlab(\"Category\") +\n  ylab(\"Frequency (%)\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\nstacked_bar_chart\n\n\n\n\n\nCode\n# create a grid of the plots\n#grid.arrange(bar_chart, sorted_bar_chart, stacked_bar_chart, ncol = 2)\n\n\nThis code creates a stacked bar chart of the item frequencies for the Pokemon “Flutter Mane”. The code first creates a sample data frame called “items” with the columns “Item” and “Freq” to represent the name of each item and its frequency. The next step involves creating a new data frame called “item_categories” which adds a third column called “Category” to the “items” data frame. The “Category” column is a factor variable that categorizes each item as “Common”, “Uncommon”, or “Rare”.\nThe code then uses the ggplot2 library to create a stacked bar chart, with the “Category” variable on the x-axis, the “Freq” variable on the y-axis, and each “Item” represented by a different color within each category. The resulting plot shows the relative frequency of each item in each category.\nThe code also contains commented-out code that creates two additional bar charts: a basic bar chart of the item frequencies and a sorted bar chart of the item frequencies. These were likely created as exploratory plots before settling on the final stacked bar chart. Finally, the code also includes commented-out code for creating a grid of the plots, but this is not used in the final output.\n\n\nFailed Attempts\n\n\nCode\n# load the necessary libraries\n\n\n# read in the data from the json file\ndata <- fromJSON(\"gen9vgc2023series2-1630_move.json\")\n\n# extract the Items data and sort by frequency\nitems <- data.frame(data$Items, stringsAsFactors = FALSE)\nitems <- items[order(-as.numeric(gsub(\"%\", \"\", items$Freq))),]\n\n# select the top 5 items\ntop_items <- head(items, 5)\n\n# create a list of ggplot objects for each item\nitem_plots <- lapply(seq_along(top_items$Item), function(i) {\n  # extract the item name and frequency\n  item <- top_items$Item[i]\n  freq <- top_items$Freq[i]\n  \n  # create a data frame for the current item\n  item_data <- data.frame(Frequency = c(freq, \"Other\"), Count = c(freq, 100 - freq))\n  \n  # create a pie chart for the item\n  p <- ggplot(item_data, aes(x = \"\", y = Count, fill = Frequency)) +\n    geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n    coord_polar(\"y\", start = 0) +\n    ggtitle(item) +\n    theme_void() +\n    theme(legend.position = \"none\")\n  \n  # return the plot object\n  return(p)\n})\n\n# arrange the plots in a grid\ngrid.arrange(grobs = item_plots, ncol = 2)\n\n\n\n\n\n\n\n\nNote\n\n\n\n> # arrange the plots in a grid > grid.arrange(grobs = item_plots, ncol = 2) Error in unit(rep(1, nrow), “null”) : ‘x’ and ‘units’ must have length > 0\nI would like to plot the item distributions but ended up with this error message.\n\n\n\n\n\n\n\n\n\n\n\nSummary\nThis blog discusses the popular online community of competitive Pokémon players, Smogon, and its battle simulator, Pokémon Showdown. The blog focuses on the development of effective visualizations using the R package igraph and ggplot2 for the comprehensive datasets available in the Smogon databases. Specifically, the blog presents codes for creating a network visualization of the top 20 Pokémon and their teammates and a stacked bar chart of item frequencies for a specific Pokémon, “Flutter Mane.” The visualizations provide insights and suggestions for building a successful Pokémon battle team and help identify patterns in the data that may be difficult to see in a table or spreadsheet format.\nOverall, the blog aims to enhance the user’s understanding of the data by presenting it in a visually engaging format to facilitate an improved decision-making process and increase the success rate of the user’s Pokémon battle team."
  },
  {
    "objectID": "posts/midterm-post/index.html#expressiveness-and-effectiveness",
    "href": "posts/midterm-post/index.html#expressiveness-and-effectiveness",
    "title": "BCB 520 - Midterm Pokemon Portfolio Post",
    "section": "Expressiveness and Effectiveness",
    "text": "Expressiveness and Effectiveness\n\nCorrected Version\n\n\n\n\n\nWrong Version\nOur main theme is about the hardness of minerals. To best demonstrate the characteristic of our elements list, I choose to visualize the index of the elements."
  },
  {
    "objectID": "posts/midterm-post/index.html#discriminability",
    "href": "posts/midterm-post/index.html#discriminability",
    "title": "BCB 520 - Midterm Pokemon Portfolio Post",
    "section": "Discriminability",
    "text": "Discriminability\n\nCorrected Version\n\n\n\n\n\nWrong Version"
  },
  {
    "objectID": "posts/midterm-post/index.html#separability",
    "href": "posts/midterm-post/index.html#separability",
    "title": "BCB 520 - Midterm Pokemon Portfolio Post",
    "section": "Separability",
    "text": "Separability\n\nCorrected Version"
  },
  {
    "objectID": "posts/midterm-post/index.html#import-data",
    "href": "posts/midterm-post/index.html#import-data",
    "title": "BCB 520 - Midterm Pokemon Portfolio Post",
    "section": "Import data",
    "text": "Import data\n\n\nCode\nlibrary(tidyverse)\n# result <- read.csv(file = 'total_elements_mindat.csv')\n#mineral <- read.csv(file = 'mineral.csv')\n# result <- read.csv(file = 'total_elements_mindat.csv')\n# df_72 <- read.csv(file = 'hardness.csv')\n#df_30 <- read.csv(file = 'hardness_30.csv')"
  },
  {
    "objectID": "posts/Practice-with-Spatial-Data/index.html",
    "href": "posts/Practice-with-Spatial-Data/index.html",
    "title": "Practice with Spatial Data",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   1.0.1 \n✔ tibble  3.1.7      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readxl)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n\n\nAttaching package: 'rnaturalearthdata'\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\n\nCode\nlibrary(dplyr)\n\nMalaria <- read.csv(\"National_Unit_data.csv\")\n\nIncidence<- Malaria%>%\n  filter(Metric == \"Infection Prevalence\" & Year == \"2019\")%>%\n  mutate(Prevalence = Value)%>%\n  select(c(ISO3, Prevalence))\n\n\n\n\nCode\nworld_map <- ne_countries(scale = 'medium', returnclass = \"sf\")\n\nmap_data <- world_map %>%\n  left_join(Incidence, by = c(\"iso_a3\" = \"ISO3\"))\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = map_data, aes(fill = Prevalence)) +\n  scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Prevalence\") +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Malaria Prevalence by Country\")\n\n\n\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = map_data, aes(fill = Prevalence)) +\n  scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Prevalence\") +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Malaria Prevalence by Country\") +\n  facet_wrap(~ region_un)\n\n\n\n\n\n\n\nCode\n# # Filter to only include infection prevalence data for a specific year\n# Year <- 2019\n# Incidence <- Malaria %>%\n#   filter(Metric == \"Incidence Rate\" & Units == \"Cases per Thousand\" & Year == Year) %>%\n#   mutate(Incidence_Rate = Value) %>%\n#   select(c(ISO3, Incidence_Rate))\n# \n# # Get world map data with medium scale\n# world_map <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n# \n# # Join incidence data with world map data\n# map_data <- world_map %>%\n#   left_join(Incidence, by = c(\"iso_a3\" = \"ISO3\"))\n# \n# # Create the choropleth map using ggplot2\n# ggplot() +\n#   geom_sf(data = map_data, aes(fill = Incidence_Rate)) +\n#   scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Incidence Rate\") +\n#   theme_minimal() +\n#   theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n#   labs(title = paste0(\"Malaria Incidence Rate by Country in \", Year))\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(dplyr)\nlibrary(gganimate)\nlibrary(transformr)\n\nMalaria <- read.csv(\"National_Unit_data.csv\")\n\nIncidence <- Malaria %>%\n  filter(Metric == \"Infection Prevalence\" & Year >= 2010 & Year <= 2020) %>%\n  mutate(Year = as.factor(Year),\n         Prevalence = Value)\n\nworld_map <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nmap_data <- world_map %>%\n  left_join(Incidence, by = c(\"iso_a3\" = \"ISO3\"))\n\np <- ggplot() +\n  geom_sf(data = map_data, aes(fill = Prevalence)) +\n  scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Prevalence\") +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Malaria Prevalence by Country\") +\n  transition_states(Year, transition_length = 2, state_length = 2)\n\nanimate(p, fps = 25, width = 800, height = 500)\n\n\nWarning in lapply(row_vars$states, as.integer): NAs introduced by coercion\n\n\nWarning in f(..., self = self): NAs introduced by coercion"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html",
    "href": "posts/Practice-with-Network-Data/index.html",
    "title": "Dubplication: Practice with Network Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing network data. Network data is characterized by two unique items that are not found in tabular or spatial data - Nodes and Links. In addition, there is a sub-type of network data that we will consider - Hierarchical or Tree data. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#igraph",
    "href": "posts/Practice-with-Network-Data/index.html#igraph",
    "title": "Dubplication: Practice with Network Data",
    "section": "IGRAPH",
    "text": "IGRAPH\nLet’s start with igraph, which is an open source toolset for network analysis. The great thing about igraph is that you can use these tools in R, Python, Mathematica, and C++. It is very flexible and very powerful.\n\nigraph in R\nFirst up, we’ll install R/igraph and load the library (note that I’ve commented out the package installation because I’ve already installed igraph on my machine):\n\n\nCode\n# install.packages(\"igraph\")\nlibrary(igraph)\n\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\n\nNow I’m going to walk you through a modified version of the igraph tutorial, which you can find here"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#creating-a-graph",
    "href": "posts/Practice-with-Network-Data/index.html#creating-a-graph",
    "title": "Dubplication: Practice with Network Data",
    "section": "Creating a graph",
    "text": "Creating a graph\nigraph offers many ways to create a graph. The simplest one is the function make_empty_graph:\n\n\nCode\ng <- make_empty_graph()\n\n\nThe most common way to create a graph is make_graph, which constructs a network based on specified edges. For example, to make a graph with 10 nodes (numbered 1 to 10) and two edges connecting nodes 1-2 and 1-5:\n\n\nCode\ng <- make_graph(edges = c(1,2, 1,5), n=10, directed = FALSE)\n\n\nWe can print the graph to get a summary of its nodes and edges:\n\n\nCode\ng\n\n\nIGRAPH ea207e5 U--- 10 2 -- \n+ edges from ea207e5:\n[1] 1--2 1--5\n\n\nThis means: Undirected Named graph with 10 vertices and 2 edges, with the exact edges listed out. If the graph has a [name] attribute, it is printed as well.\n\n\n\n\n\n\nNote\n\n\n\nsummary does not list the edges, which is convenient for large graphs with millions of edges:\n\n\n\n\nCode\nsummary(g)\n\n\nIGRAPH ea207e5 U--- 10 2 -- \n\n\nThe same function make_graph can create some notable graphs by just specifying their name. For example you can create the graph that represents the social network of Zachary’s karate club, that shows the friendship between 34 members of a karate club at a US university in the 1970s:\n\n\nCode\ng <- make_graph('Zachary')\n\n\nTo visualize a graph you can use plot:\n\n\nCode\nplot(g)"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#vertex-and-edge-ids",
    "href": "posts/Practice-with-Network-Data/index.html#vertex-and-edge-ids",
    "title": "Dubplication: Practice with Network Data",
    "section": "Vertex and edge IDs",
    "text": "Vertex and edge IDs\nVertices and edges have numerical vertex IDs in igraph. Vertex IDs are always consecutive and they start with 1. For a graph with n vertices the vertex IDs are always between 1 and n. If some operation changes the number of vertices in the graphs, e.g. a subgraph is created via induced_subgraph, then the vertices are renumbered to satisfy this criterion.\nThe same is true for the edges as well: edge IDs are always between 1 and m, the total number of edges in the graph.\nIn addition to IDs, vertices and edges can be assigned a name and other attributes. That makes it easier to track them whenever the graph is altered."
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#addingdeleting-vertices-and-edges",
    "href": "posts/Practice-with-Network-Data/index.html#addingdeleting-vertices-and-edges",
    "title": "Dubplication: Practice with Network Data",
    "section": "Adding/deleting vertices and edges",
    "text": "Adding/deleting vertices and edges\nLet’s continue working with the Karate club graph. To add one or more vertices to an existing graph, use add_vertices:\n\n\nCode\ng <- add_vertices(g, 3)\n\n\nSimilarly, to add edges you can use add_edges:\n\n\nCode\ng <- add_edges(g, edges = c(1,35, 1,36, 34,37))\n\n\nEdges are added by specifying the source and target vertex IDs for each edge. This call added three edges, one connecting vertices 1 and 35, one connecting vertices 1 and 36, and one connecting vertices 34 and 37.\nIn addition to the add_vertices and add_edges functions, the plus operator can be used to add vertices or edges to graph. The actual operation that is performed depends on the type of the right hand side argument:\n\n\nCode\ng <- g + edges(c(1,35, 1,36, 34,37))\n\n\nYou can add a single vertex/edge at a time using add_vertex and add_edge.\nLet us add some more vertices and edges to our graph. In igraph we can use the magrittr package, which provides a mechanism for chaining commands with the operator %\\>%:\n\n\nCode\ng <- g %>% add_edges(edges=c(1,34)) %>% add_vertices(3) %>%\n     add_edges(edges=c(38,39, 39,40, 40,38, 40,37))\ng\n\n\nIGRAPH 2293648 U--- 40 86 -- Zachary\n+ attr: name (g/c)\n+ edges from 2293648:\n [1]  1-- 2  1-- 3  1-- 4  1-- 5  1-- 6  1-- 7  1-- 8  1-- 9  1--11  1--12\n[11]  1--13  1--14  1--18  1--20  1--22  1--32  2-- 3  2-- 4  2-- 8  2--14\n[21]  2--18  2--20  2--22  2--31  3-- 4  3-- 8  3--28  3--29  3--33  3--10\n[31]  3-- 9  3--14  4-- 8  4--13  4--14  5-- 7  5--11  6-- 7  6--11  6--17\n[41]  7--17  9--31  9--33  9--34 10--34 14--34 15--33 15--34 16--33 16--34\n[51] 19--33 19--34 20--34 21--33 21--34 23--33 23--34 24--26 24--28 24--33\n[61] 24--34 24--30 25--26 25--28 25--32 26--32 27--30 27--34 28--34 29--32\n[71] 29--34 30--33 30--34 31--33 31--34 32--33 32--34 33--34  1--35  1--36\n+ ... omitted several edges\n\n\nCode\nplot(g)\n\n\n\n\n\nWe now have an undirected graph with 40 vertices and 86 edges. Vertex and edge IDs are always contiguous, so if you delete a vertex all subsequent vertices will be renumbered. When a vertex is renumbered, edges are not renumbered, but their source and target vertices will be. Use delete_vertices and delete_edges to perform these operations. For instance, to delete the edge connecting vertices 1-34, get its ID and then delete it:\n\n\nCode\nget.edge.ids(g, c(1,34))\n\n\n[1] 82\n\n\n\n\nCode\ng <- delete_edges(g, 82)\n\n\nAs an example, to create a broken ring:\n\n\nCode\ng <- make_ring(10) %>% delete_edges(\"10|1\")\nplot(g)\n\n\n\n\n\nThe example above shows that you can also refer to edges with strings containing the IDs of the source and target vertices, connected by a pipe symbol |. \"10|1\" in the above example means the edge that connects vertex 10 to vertex 1. Of course you can also use the edge IDs directly, or retrieve them with the get.edge.ids function:\n\n\nCode\ng <- make_ring(5)\ng <- delete_edges(g, get.edge.ids(g, c(1,5, 4,5)))\nplot(g)"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#constructing-graphs",
    "href": "posts/Practice-with-Network-Data/index.html#constructing-graphs",
    "title": "Dubplication: Practice with Network Data",
    "section": "Constructing graphs",
    "text": "Constructing graphs\nIn addition to make_empty_graph, make_graph, and make_graph_from_literal, igraph includes many other function to construct a graph. Some are deterministic, i.e. they produce the same graph each single time, e.g. make_tree:\n\n\nCode\ngraph1 <- make_tree(127, 2, mode = \"undirected\")\nsummary(graph1)\n\n\nIGRAPH 419788f U--- 127 126 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a regular tree graph with 127 vertices, each vertex having two children. No matter how many times you call make_tree, the generated graph will always be the same if you use the same parameters:\n\n\nCode\ngraph2 <- make_tree(127, 2, mode = \"undirected\")\n\n\n\n\nCode\nidentical_graphs(graph1,graph2)\n\n\n[1] TRUE\n\n\nOther functions generate graphs stochastically, i.e. they produce a different graph each time. For instance sample_grg:\n\n\nCode\ngraph1 <- sample_grg(100, 0.2)\nsummary(graph1)\n\n\nIGRAPH 511f5d0 U--- 100 479 -- Geometric random graph\n+ attr: name (g/c), radius (g/n), torus (g/l)\n\n\nCode\nplot(graph1)\n\n\n\n\n\nThis generates a geometric random graph: n points are chosen randomly and uniformly inside the unit square and pairs of points closer to each other than a predefined distance d are connected by an edge. If you generate GRGs with the same parameters, they will be different:\n\n\nCode\ngraph2 <- sample_grg(100, 0.2)\nidentical_graphs(graph1, graph2)\n\n\n[1] FALSE\n\n\nCode\nplot(graph2)\n\n\n\n\n\nA slightly looser way to check if the graphs are equivalent is via isomorphic. Two graphs are said to be isomorphic if they have the same number of components (vertices and edges) and maintain a one-to-one correspondence between vertices and edges, i.e., they are connected in the same way.\n\n\nCode\nisomorphic(graph1, graph2)\n\n\n[1] FALSE\n\n\nChecking for isomorphism can take a while for large graphs (in this case, the answer can quickly be given by checking the degree sequence of the two graphs). identical_graph is a stricter criterion than isomorphic: the two graphs must have the same list of vertices and edges, in exactly the same order, with same directedness, and the two graphs must also have identical graph, vertex and edge attributes."
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#setting-and-retrieving-attributes",
    "href": "posts/Practice-with-Network-Data/index.html#setting-and-retrieving-attributes",
    "title": "Dubplication: Practice with Network Data",
    "section": "Setting and retrieving attributes",
    "text": "Setting and retrieving attributes\nIn addition to IDs, vertex and edges can have attributes such as a name, coordinates for plotting, metadata, and weights. The graph itself can have such attributes too (e.g. a name, which will show in summary). In a sense, every graph, vertex and edge can be used as an R namespace to store and retrieve these attributes.\nTo demonstrate the use of attributes, let us create a simple social network:\n\n\nCode\ng <- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther)\n\n\nEach vertex represents a person, so we want to store ages, genders and types of connection between two people (is_formal refers to whether a connection between one person or another is formal or informal, i.e. colleagues or friends). The \\$ operator is a shortcut to get and set graph attributes. It is shorter and just as readable as graph_attr and set_graph_attr.\n\n\nCode\nV(g)$age <- c(25, 31, 18, 23, 47, 22, 50) \nV(g)$gender <- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\nE(g)$is_formal <- c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE)\nsummary(g)\n\n\nIGRAPH 7eef2d3 UN-- 7 9 -- \n+ attr: name (v/c), age (v/n), gender (v/c), is_formal (e/l)\n\n\nV and E are the standard way to obtain a sequence of all vertices and edges, respectively. This assigns an attribute to all vertices/edges at once. Another way to generate our social network is with the use of set_vertex_attr and set_edge_attr and the operator %\\>%:\n\n\nCode\ng <- make_graph(~ Alice-Bob:Claire:Frank, Claire-Alice:Dennis:Frank:Esther,\n                George-Dennis:Frank, Dennis-Esther) %>%\n  set_vertex_attr(\"age\", value = c(25, 31, 18, 23, 47, 22, 50)) %>%\n  set_vertex_attr(\"gender\", value = c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")) %>%\n  set_edge_attr(\"is_formal\", value = c(FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE))\nsummary(g)\n\n\nTo assign or modify an attribute for a single vertex/edge:\n\n\nCode\nE(g)$is_formal\n\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nCode\nE(g)$is_formal[1] <- TRUE\nE(g)$is_formal\n\n\n[1]  TRUE FALSE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE\n\n\nAttribute values can be set to any R object, but note that storing the graph in some file formats might result in the loss of complex attribute values. Vertices, edges and the graph itself can all be used to set attributes, e.g. to add a date to the graph:\n\n\nCode\ng$date <- c(\"2022-02-11\")\ngraph_attr(g, \"date\")\n\n\n[1] \"2022-02-11\"\n\n\nTo retrieve attributes, you can also use graph_attr, vertex_attr, and edge_attr. To find the ID of a vertex you can use the function match:\n\n\nCode\nmatch(c(\"George\"), V(g)$name)\n\n\n[1] 7\n\n\nTo assign attributes to a subset of vertices or edges, you can use:\n\n\nCode\nV(g)$name[1:3] <- c(\"Alejandra\", \"Bruno\", \"Carmina\")\nV(g)\n\n\n+ 7/7 vertices, named, from 7eef2d3:\n[1] Alejandra Bruno     Carmina   Frank     Dennis    Esther    George   \n\n\nTo delete attributes:\n\n\nCode\ng <- delete_vertex_attr(g, \"gender\")\nV(g)$gender\n\n\nNULL\n\n\nIf you want to save a graph in R with all the attributes use the R’s standard function dput function and retrieve it later with dget. You can also just save the R workspace and restore it later."
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#structural-properties-of-graphs",
    "href": "posts/Practice-with-Network-Data/index.html#structural-properties-of-graphs",
    "title": "Dubplication: Practice with Network Data",
    "section": "Structural properties of graphs",
    "text": "Structural properties of graphs\nigraph provides a large set of functions to calculate various structural properties of graphs. It is beyond the scope of this tutorial to document all of them, hence this section will only introduce a few of them for illustrative purposes. We will work on the small social network constructed in the previous section.\nPerhaps the simplest property one can think of is the degree. The degree of a vertex equals the number of edges adjacent to it. In case of directed networks, we can also define in-degree (the number of edges pointing towards the vertex) and out-degree (the number of edges originating from the vertex). igraph is able to calculate all of them using a simple syntax:\n\n\nCode\ndegree(g)\n\n\nAlejandra     Bruno   Carmina     Frank    Dennis    Esther    George \n        3         1         4         3         3         2         2 \n\n\nIf the graph was directed, we would have been able to calculate the in- and out-degrees separately using degree(mode=\"in\") and degree(mode=\"out\"). You can also pass a single vertex ID or a list of vertex IDs to degree if you want to calculate the degrees for only a subset of vertices:\n\n\nCode\ndegree(g, 7)\n\n\nGeorge \n     2 \n\n\n\n\nCode\ndegree(g, v=c(3,4,5))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nMost functions that accept vertex IDs also accept vertex names (i.e. the values of the name vertex attribute) as long as the names are unique:\n\n\nCode\ndegree(g, v=c(\"Carmina\", \"Frank\", \"Dennis\"))\n\n\nCarmina   Frank  Dennis \n      4       3       3 \n\n\nIt also works for single vertices:\n\n\nCode\ndegree(g, \"Bruno\")\n\n\nBruno \n    1 \n\n\nA similar syntax is used for most of the structural properties igraph can calculate. For vertex properties, the functions accept a vertex ID, a vertex name, or a list of vertex IDs or names (and if they are omitted, the default is the set of all vertices). For edge properties, the functions accept a single edge ID or a list of edge IDs.\n\nNOTE: For some measures, it does not make sense to calculate them only for a few vertices or edges instead of the whole graph, as it would take the same time anyway. In this case, the functions won’t accept vertex or edge IDs, but you can still restrict the resulting list later using standard operations. One such example is eigenvector centrality (evcent()).\n\nBesides degree, igraph includes built-in routines to calculate many other centrality properties, including vertex and edge betweenness (edge_betweenness) or Google’s PageRank (page_rank) just to name a few. Here we just illustrate edge betweenness:\n\n\nCode\nedge_betweenness(g)\n\n\n[1] 6 6 4 3 4 4 4 2 3\n\n\nNow we can also figure out which connections have the highest betweenness centrality:\n\n\nCode\nebs <- edge_betweenness(g)\nas_edgelist(g)[ebs == max(ebs), ]\n\n\n     [,1]        [,2]     \n[1,] \"Alejandra\" \"Bruno\"  \n[2,] \"Alejandra\" \"Carmina\""
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#querying-vertices-and-edges-based-on-attributes",
    "href": "posts/Practice-with-Network-Data/index.html#querying-vertices-and-edges-based-on-attributes",
    "title": "Dubplication: Practice with Network Data",
    "section": "Querying vertices and edges based on attributes",
    "text": "Querying vertices and edges based on attributes\n\nSelecting vertices\nImagine that in a given social network, you want to find out who has the largest degree. You can do that with the tools presented so far and the which.max function:\n\n\nCode\nwhich.max(degree(g))\n\n\nCarmina \n      3 \n\n\nAnother example would be to select only vertices that have only odd IDs but not even ones, using the V function:\n\n\nCode\ngraph <- graph.full(n=10)\nonly_odd_vertices <- which(V(graph)%%2==1)\nlength(only_odd_vertices)\n\n\n[1] 5\n\n\nOf course, it is possible to select vertices or edges by positional indices:\n\n\nCode\nseq <- V(graph)[2, 3, 7]\nseq\n\n\n+ 3/10 vertices, from 8ed1cf5:\n[1] 2 3 7\n\n\n\n\nCode\nseq <- seq[1, 3]    # filtering an existing vertex set\nseq\n\n\n+ 2/10 vertices, from 8ed1cf5:\n[1] 2 7\n\n\nSelecting a vertex that does not exist results in an error:\n\n\nCode\nseq <- V(graph)[2, 3, 7, \"foo\", 3.5]\n## Error in simple_vs_index(x, ii, na_ok) : Unknown vertex selected\n\n\nAttribute names can also be used as-is within the indexing brackets of V() and E(). This can be combined with R’s ability to use boolean vectors for indexing to obtain very concise and readable expressions to retrieve a subset of the vertex or edge set of a graph. For instance, the following command gives you the names of the individuals younger than 30 years in our social network:\n\n\nCode\nV(g)[age < 30]$name\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Frank\"     \"Esther\"   \n\n\nOf course, < is not the only boolean operator that can be used for this. Other possibilities include the following:\n\n\n\n\n\n\n\nOperator\nMeaning\n\n\n\n\n==\nThe attribute/property value must be equal to\n\n\n!=\nThe attribute/property value must not be equal to\n\n\n<\nThe attribute/property value must be less than\n\n\n<=\nThe attribute/property value must be less than or equal to\n\n\n>\nThe attribute/property value must be greater than\n\n\n>=\nThe attribute/property value must be greater than or equal to\n\n\n%in%\nThe attribute/property value must be included in\n\n\n\nYou can also create a “not in” operator from %in% using the Negate function:\n\n\nCode\n`%notin%` <- Negate(`%in%`)\n\n\nIf an attribute has the same name as an igraph function, you should be careful as the syntax can become a little confusing. For instance, if there is an attribute named degree that represents the grades of an exam for each person, that should not be confused with the igraph function that computes the degrees of vertices in a network sense:\n\n\nCode\nV(g)$degree <- c(\"A\", \"B\", \"B+\", \"A+\", \"C\", \"A\", \"B\")\nV(g)$degree[degree(g) == 3]\n\n\n[1] \"A\"  \"A+\" \"C\" \n\n\n\n\nCode\nV(g)$name[degree(g) == 3]\n\n\n[1] \"Alejandra\" \"Frank\"     \"Dennis\"   \n\n\n\n\nSelecting edges\nEdges can be selected based on attributes just like vertices. As mentioned above, the standard way to get edges is E. Moreover, there are a few special structural properties for selecting edges.\nUsing .from allows you to filter the edge sequence based on the source vertices of the edges. E.g., to select all the edges originating from Carmina (who has vertex index 3):\n\n\nCode\nE(g)[.from(3)]\n\n\n+ 4/9 edges from 7eef2d3 (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nOf course it also works with vertex names:\n\n\nCode\nE(g)[.from(\"Carmina\")]\n\n\n+ 4/9 edges from 7eef2d3 (vertex names):\n[1] Alejandra--Carmina Carmina  --Frank   Carmina  --Dennis  Carmina  --Esther \n\n\nUsing .to filters edge sequences based on the target vertices. This is different from .from if the graph is directed, while it gives the same answer for undirected graphs. Using .inc selects only those edges that are incident on a single vertex or at least one of the vertices, irrespectively of the edge directions.\nThe %--% operator can be used to select edges between specific groups of vertices, ignoring edge directions in directed graphs. For instance, the following expression selects all the edges between Carmina (vertex index 3), Dennis (vertex index 5) and Esther (vertex index 6):\n\n\nCode\nE(g) [ 3:5 %--% 5:6 ]\n\n\n+ 3/9 edges from 7eef2d3 (vertex names):\n[1] Carmina--Dennis Carmina--Esther Dennis --Esther\n\n\nTo make the %--% operator work with names, you can build string vectors containing the names and then use these vectors as operands. For instance, to select all the edges that connect men to women, we can do the following after re-adding the gender attribute that we deleted earlier:\n\n\nCode\nV(g)$gender <- c(\"f\", \"m\", \"f\", \"m\", \"m\", \"f\", \"m\")\n\n\n\n\nCode\nmen <- V(g)[gender == \"m\"]$name\nmen\n\n\n[1] \"Bruno\"  \"Frank\"  \"Dennis\" \"George\"\n\n\n\n\nCode\nwomen <- V(g)[gender == \"f\"]$name\nwomen\n\n\n[1] \"Alejandra\" \"Carmina\"   \"Esther\"   \n\n\n\n\nCode\nE(g)[men %--% women]\n\n\n+ 5/9 edges from 7eef2d3 (vertex names):\n[1] Alejandra--Bruno  Alejandra--Frank  Carmina  --Frank  Carmina  --Dennis\n[5] Dennis   --Esther"
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#treating-a-graph-as-an-adjacency-matrix",
    "href": "posts/Practice-with-Network-Data/index.html#treating-a-graph-as-an-adjacency-matrix",
    "title": "Dubplication: Practice with Network Data",
    "section": "Treating a graph as an adjacency matrix",
    "text": "Treating a graph as an adjacency matrix\nThe adjacency matrix is another way to represent a graph. In an adjacency matrix, rows and columns are labeled by graph vertices, and the elements of the matrix indicate the number of edges between vertices i and j. The adjacency matrix for the example graph is:\n\n\nCode\nget.adjacency(g)\n\n\n7 x 7 sparse Matrix of class \"dgCMatrix\"\n          Alejandra Bruno Carmina Frank Dennis Esther George\nAlejandra         .     1       1     1      .      .      .\nBruno             1     .       .     .      .      .      .\nCarmina           1     .       .     1      1      1      .\nFrank             1     .       1     .      .      .      1\nDennis            .     .       1     .      .      1      1\nEsther            .     .       1     .      1      .      .\nGeorge            .     .       .     1      1      .      .\n\n\nFor example, Carmina (1, 0, 0, 1, 1, 1, 0) is directly connected to Alejandra (who has vertex index 1), Frank (index 4), Dennis (index 5) and Esther (index 6), but not to Bruno (index 2) or to George (index 7)."
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#layouts-and-plotting",
    "href": "posts/Practice-with-Network-Data/index.html#layouts-and-plotting",
    "title": "Dubplication: Practice with Network Data",
    "section": "Layouts and plotting",
    "text": "Layouts and plotting\nA graph is an abstract mathematical object without a specific representation in 2D, 3D or any other geometric space. This means that whenever we want to visualise a graph, we have to find a mapping from vertices to coordinates in two- or three-dimensional space first, preferably in a way that is useful and/or pleasing for the eye. A separate branch of graph theory, namely graph drawing, tries to solve this problem via several graph layout algorithms. igraph implements quite a few layout algorithms and is also able to draw them onto the screen or to any output format that R itself supports.\n\nLayout algorithms\nThe layout functions in igraph always start with layout. The following table summarises them:\n\n\n\n\n\n\n\nMethod name\nAlgorithm description\n\n\n\n\nlayout_randomly\nPlaces the vertices completely randomly\n\n\nlayout_in_circle\nDeterministic layout that places the vertices on a circle\n\n\nlayout_on_sphere\nDeterministic layout that places the vertices evenly on the surface of a sphere\n\n\nlayout_with_drl\nThe Drl (Distributed Recursive Layout) algorithm for large graphs\n\n\nlayout_with_fr\nFruchterman-Reingold force-directed algorithm\n\n\nlayout_with_kk\nKamada-Kawai force-directed algorithm\n\n\nlayout_with_lgl\nThe LGL (Large Graph Layout) algorithm for large graphs\n\n\nlayout_as_tree\nReingold-Tilford tree layout, useful for (almost) tree-like graphs\n\n\nlayout_nicely\nLayout algorithm that automatically picks one of the other algorithms based on certain properties of the graph\n\n\n\nLayout algorithms can be called directly with a graph as its first argument. They will return a matrix with two columns and as many rows as the number of vertices in the graph; each row will correspond to the position of a single vertex, ordered by vertex IDs. Some algorithms have a 3D variant; in this case they return three columns instead of 2.\n\n\nCode\nlayout <- layout_with_kk(g)\n\n\nSome layout algorithms take additional arguments; e.g., when laying out a graph as a tree, it might make sense to specify which vertex is to be placed at the root of the layout:\n\n\nCode\nlayout <- layout_as_tree(g, root = 2)\n\n\n\n\nDrawing a graph using a layout\nWe can plot our imaginary social network with the Kamada-Kawai layout algorithm as follows:\n\n\nCode\nlayout <- layout_nicely(g)\n\n\n\n\nCode\nplot(g, layout = layout, main = \"Social network with the Kamada-Kawai layout algorithm\")\n\n\n\n\n\nThis should open a new window showing a visual representation of the network. Remember that the exact placement of nodes may be different on your machine since the layout is not deterministic.\nThe layout argument also accepts functions; in this case, the function will be called with the graph as its first argument. This makes it possible to just pass the name of a layout function directly, without creating a layout variable:\n\n\nCode\nplot(g, layout = layout_with_fr,\n     main = \"Social network with the Fruchterman-Reingold layout algorithm\")\n\n\n\n\n\nTo improve the visuals, a trivial addition would be to color the vertices according to the gender. We should also try to place the labels slightly outside the vertices to improve readability:\n\n\nCode\nV(g)$color <- ifelse(V(g)$gender == \"m\", \"yellow\", \"red\")\nplot(g, layout = layout, vertex.label.dist = 3.5,\n     main = \"Social network - with genders as colors\")\n\n\n\n\n\nYou can also treat the gender attribute as a factor and provide the colors with an argument to plot(), which takes precedence over the color vertex attribute. Colors will be assigned automatically to levels of a factor:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.color=as.factor(V(g)$gender))\n\n\n\n\n\nAs seen above with the vertex.color argument, you can specify visual properties as arguments to plot instead of using vertex or edge attributes. The following plot shows the formal ties with thick lines while informal ones with thin lines:\n\n\nCode\nplot(g, layout=layout, vertex.label.dist=3.5, vertex.size=20,\n     vertex.color=ifelse(V(g)$gender == \"m\", \"yellow\", \"red\"),\n     edge.width=ifelse(E(g)$is_formal, 5, 1))\n\n\n\n\n\nThis latter approach is preferred if you want to keep the properties of the visual representation of your graph separate from the graph itself.\nIn summary, there are special vertex and edge properties that correspond to the visual representation of the graph. These attributes override the default settings of igraph (i.e color, weight, name, shape,layout,etc.). The following two tables summarise the most frequently used visual attributes for vertices and edges, respectively:\n\n\nVertex attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nvertex.color\nColor of the vertex\n\n\nlabel\nvertex.label\nLabel of the vertex. They will be converted to character. Specify NA to omit vertex labels. The default vertex labels are the vertex ids.\n\n\nlabel.cex\nvertex.label.cex\nFont size of the vertex label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nvertex.label.color\nColor of the vertex label\n\n\nlabel.degree\nvertex.label.degree\nIt defines the position of the vertex labels, relative to the center of the vertices. It is interpreted as an angle in radian, zero means ‘to the right’, and ‘pi’ means to the left, up is -pi/2 and down is pi/2. The default value is -pi/4\n\n\nlabel.dist\nvertex.label.dist\nDistance of the vertex label from the vertex itself, relative to the vertex size\n\n\nlabel.family\nvertex.label.family\nFont family of the vertex, similarly to R’s text function\n\n\nlabel.font\nvertex.label.font\nFont within the font family of the vertex, similarly to R’s text function\n\n\nshape\nvertex.shape\nThe shape of the vertex, currently “circle”, “square”, “csquare”, “rectangle”, “crectangle”, “vrectangle”, “pie” (see vertex.shape.pie), ‘sphere’, and “none” are supported, and only by the plot.igraph command.\n\n\nsize\nvertex.size\nThe size of the vertex, a numeric scalar or vector, in the latter case each vertex sizes may differ\n\n\n\n\n\nEdge attributes controlling graph plots\n\n\n\n\n\n\n\n\nAttribute name\nKeyword argument\nPurpose\n\n\n\n\ncolor\nedge.color\nColor of the edge\n\n\ncurved\nedge.curved\nA numeric value specifies the curvature of the edge; zero curvature means straight edges, negative values means the edge bends clockwise, positive values the opposite. TRUE means curvature 0.5, FALSE means curvature zero\n\n\narrow.size\nedge.arrow.size\nCurrently this is a constant, so it is the same for every edge. If a vector is submitted then only the first element is used, ie. if this is taken from an edge attribute then only the attribute of the first edge is used for all arrows.\n\n\narrow.width\nedge.arrow.width\nThe width of the arrows. Currently this is a constant, so it is the same for every edge\n\n\nwidth\nedge.width\nWidth of the edge in pixels\n\n\nlabel\nedge.label\nIf specified, it adds a label to the edge.\n\n\nlabel.cex\nedge.label.cex\nFont size of the edge label, interpreted as a multiplicative factor, similarly to R’s text function\n\n\nlabel.color\nedge.label.color\nColor of the edge label\n\n\nlabel.family\nedge.label.family\nFont family of the edge, similarly to R’s text function\n\n\nlabel.font\nedge.label.font\nFont within the font family of the edge, similarly to R’s text function\n\n\n\n\n\nGeneric arguments of plot()\nThese settings can be specified as arguments to the plot function to control the overall appearance of the plot.\n\n\n\n\n\n\n\nKeyword argument\nPurpose\n\n\n\n\nlayout\nThe layout to be used. It can be an instance of Layout, a list of tuples containing X-Y coordinates, or the name of a layout algorithm. The default is auto, which selects a layout algorithm automatically based on the size and connectedness of the graph.\n\n\nmargin\nThe amount of empty space below, over, at the left and right of the plot, it is a numeric vector of length four."
  },
  {
    "objectID": "posts/Practice-with-Network-Data/index.html#assignment",
    "href": "posts/Practice-with-Network-Data/index.html#assignment",
    "title": "Dubplication: Practice with Network Data",
    "section": "ASSIGNMENT",
    "text": "ASSIGNMENT\nImprove the network above by:\n\nColoring the edges according to Advisor / BCB520 attribute.\nColoring the nodes according to Department.\nAdujsting the labels to improve readability."
  }
]